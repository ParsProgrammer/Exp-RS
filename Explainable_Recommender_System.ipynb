{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# uncomment the last two cell to clone the data and enable the GPU\n",
        "#! git clone https://github.com/ParsProgrammer/ERS.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cd ERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrzVYQNxJm_W",
        "outputId": "8f98d417-6c2d-47ff-a041-84238103eba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.9 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (14.0.6)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (3.19.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.50.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (4.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (0.26.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (2.9.1)\n",
            "Requirement already satisfied: packaging in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (21.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (61.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (2.9.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (3.7.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.12)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.9) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.9.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.2.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.28.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from packaging->tensorflow-gpu==2.9) (3.0.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (4.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-text in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (2.9.0)\n",
            "Requirement already satisfied: tensorflow<2.10,>=2.9.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-text) (2.9.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.16.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (14.0.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (61.2.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.7.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.50.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: packaging in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (21.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.26.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.12.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2022.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow-gpu==2.9\n",
        "%pip install tensorflow-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BTOV54y-ckzq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (3.5.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (4.34.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (9.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1u4wpNQOEUc9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import gc\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import KFold\n",
        "import datetime \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTkARkSuo9PR",
        "outputId": "8548446d-69cd-4727-8b8f-851569dd33d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim==3.8.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (3.8.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from gensim==3.8.3) (1.16.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from gensim==3.8.3) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from gensim==3.8.3) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from gensim==3.8.3) (6.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: nltk in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (3.7)\n",
            "Requirement already satisfied: click in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: joblib in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from nltk) (2022.7.25)\n",
            "Requirement already satisfied: importlib-metadata in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from click->nltk) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim==3.8.3\n",
        "%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnDuJU4fpMLE",
        "outputId": "ecfd7d10-b929-43ce-cd99-0e2213f4e376"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/mobin/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-25 11:38:02.482455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-25 11:38:02.494084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-25 11:38:02.494253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-25 11:38:02.495114: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-25 11:38:02.496888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-25 11:38:02.497109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-25 11:38:02.497213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-25 11:38:02.807472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-25 11:38:02.807645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-25 11:38:02.807763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-25 11:38:02.807860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2132 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "else :\n",
        "  print(\"No GPU available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (2.9.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (2.9.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (2.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (61.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (2.2.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (1.50.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (4.12.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorboard_plugin_profile in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (2.11.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard_plugin_profile) (61.2.0)\n",
            "Requirement already satisfied: gviz-api>=1.9.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard_plugin_profile) (1.10.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard_plugin_profile) (3.19.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard_plugin_profile) (1.16.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard_plugin_profile) (2.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard_plugin_profile) (2.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorboard\n",
        "%pip install -U tensorboard_plugin_profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim.summarization.summarizer import summarize\n",
        "from gensim.summarization import keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vaderSentiment in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from vaderSentiment) (2.28.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests->vaderSentiment) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests->vaderSentiment) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests->vaderSentiment) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests->vaderSentiment) (1.26.11)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyypFCrlw2SV"
      },
      "source": [
        "# **Data Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p7IbgFIxRQb-"
      },
      "outputs": [],
      "source": [
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    name=b'\"verified\": \\\"true\\\",'\n",
        "    l=l.replace(b'\"verified\": true,',bytes(name))\n",
        "    name1=b'\"verified\": \\\"false\\\",'\n",
        "    l=l.replace(b'\"verified\": false,',bytes(name))\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('reviews_Grocery_and_Gourmet_Food_5.json.gz')\n",
        "\n",
        "# dataset link\n",
        "# Grocery and Gourmet Food\n",
        "# https://jmcauley.ucsd.edu/data/amazon/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_auxwvSRYsvu"
      },
      "source": [
        "Dataset Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E9FGFZINRQOn",
        "outputId": "0dad1216-9ec6-4528-fa44-32ab26a94602"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1VEELTKS8NLZB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A14R9XMZVJ6INB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I bought this on impulse and it comes from Jap...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A27IQHDZFQFNGG</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Really good. Great gift for any fan of green t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A31QY5TASILE89</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I had never had it before, was curious to see ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A2LWK003FFMCI5</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I've been looking forward to trying these afte...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151249</th>\n",
              "      <td>A2L6QS8SVHT9RG</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>Delicious gluten-free oatmeal: we tried both t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151250</th>\n",
              "      <td>AFJFXN42RZ3G2</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>With the many selections of instant oatmeal ce...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151251</th>\n",
              "      <td>ASEBX8TBYWQWA</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>While I usually review CDs and DVDs, as well a...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151252</th>\n",
              "      <td>ANKQGTXHREOI5</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>My son and I enjoyed these oatmeal packets.  H...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151253</th>\n",
              "      <td>A2CF66KIQ3RKX3</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>I like to eat oatmeal i the mornings. I usuall...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151254 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                userID      itemID  \\\n",
              "0       A1VEELTKS8NLZB  616719923X   \n",
              "1       A14R9XMZVJ6INB  616719923X   \n",
              "2       A27IQHDZFQFNGG  616719923X   \n",
              "3       A31QY5TASILE89  616719923X   \n",
              "4       A2LWK003FFMCI5  616719923X   \n",
              "...                ...         ...   \n",
              "151249  A2L6QS8SVHT9RG  B00KCJRVO2   \n",
              "151250   AFJFXN42RZ3G2  B00KCJRVO2   \n",
              "151251   ASEBX8TBYWQWA  B00KCJRVO2   \n",
              "151252   ANKQGTXHREOI5  B00KCJRVO2   \n",
              "151253  A2CF66KIQ3RKX3  B00KCJRVO2   \n",
              "\n",
              "                                               reviewText  rating  \n",
              "0       Just another flavor of Kit Kat but the taste i...     4.0  \n",
              "1       I bought this on impulse and it comes from Jap...     3.0  \n",
              "2       Really good. Great gift for any fan of green t...     4.0  \n",
              "3       I had never had it before, was curious to see ...     5.0  \n",
              "4       I've been looking forward to trying these afte...     4.0  \n",
              "...                                                   ...     ...  \n",
              "151249  Delicious gluten-free oatmeal: we tried both t...     4.0  \n",
              "151250  With the many selections of instant oatmeal ce...     4.0  \n",
              "151251  While I usually review CDs and DVDs, as well a...     5.0  \n",
              "151252  My son and I enjoyed these oatmeal packets.  H...     4.0  \n",
              "151253  I like to eat oatmeal i the mornings. I usuall...     4.0  \n",
              "\n",
              "[151254 rows x 4 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.rename(columns={\"reviewerID\": \"userID\", \"asin\": \"itemID\",\"overall\":\"rating\"},inplace=True)\n",
        "df=df[['userID','itemID','reviewText','rating']]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYb9dMRLXjZT"
      },
      "source": [
        "# **Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yY4NJsolgtl"
      },
      "source": [
        "**User Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9kPFQ1GJr_I"
      },
      "source": [
        "determining all unique users with their reviews and ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "l_eSbOjWRQD3",
        "outputId": "63fd7abe-5957-46a2-aa85-8ca3721bdec5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>itemID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00177463W0XWB16A9O05</td>\n",
              "      <td>[It is a good stand by coffee you can count on...</td>\n",
              "      <td>[B0029XDZIK, B003C4YIFE, B003YUW7EK, B00474OR8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A022899328A0QROR32DCT</td>\n",
              "      <td>[awesome texture for even the gluten eating ea...</td>\n",
              "      <td>[B000EVE3Y4, B001ACMCNU, B003TO9RSU, B003V8QGA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A04309042SDSL8YX2HRR7</td>\n",
              "      <td>[I love roasted garlic &amp; sweet bell peppers. Y...</td>\n",
              "      <td>[B000B6J51I, B000EM6Q34, B000FYXBPW, B003VN74V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A068255029AHTHDXZURNU</td>\n",
              "      <td>[These bars are especially delicious for cocon...</td>\n",
              "      <td>[B000HKFF94, B000K8WVYA, B001FA1K2G, B00474VPY...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A06944662TFWOKKV4GJKX</td>\n",
              "      <td>[UGH!  My stomach has been really killing me l...</td>\n",
              "      <td>[B000CMD63E, B000CQBZPG, B000GFYRHG, B000GZYAR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14676</th>\n",
              "      <td>AZWRZZAMX90VT</td>\n",
              "      <td>[Very nice. Not spicy, not too salty, lots of ...</td>\n",
              "      <td>[B0007R9L4M, B0007R9L5Q, B000CN7BMA, B000CQ01G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14677</th>\n",
              "      <td>AZXKAH2DE6C8A</td>\n",
              "      <td>[Could not imagine having such a rich tasting ...</td>\n",
              "      <td>[B0004N14BC, B0005XOVY8, B000EML7DS, B000EOXQR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14678</th>\n",
              "      <td>AZXON596A1VXC</td>\n",
              "      <td>[I was a bit skeptical when I bought this prod...</td>\n",
              "      <td>[B00113SKZW, B00113ZTVK, B001EO5RCM, B001EO5S0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14679</th>\n",
              "      <td>AZYXC63SS008M</td>\n",
              "      <td>[This is just about the healthiest you can get...</td>\n",
              "      <td>[B000NGNEKY, B0039LVLS2, B0040QCJDG, B0040WCQK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14680</th>\n",
              "      <td>AZZ5ASC403N74</td>\n",
              "      <td>[Everybody loves homemade spaghetti sauce, but...</td>\n",
              "      <td>[B0035N3ADS, B004FEN3GA, B004U49QU2, B00BIEU5P...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14681 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      userID  \\\n",
              "0      A00177463W0XWB16A9O05   \n",
              "1      A022899328A0QROR32DCT   \n",
              "2      A04309042SDSL8YX2HRR7   \n",
              "3      A068255029AHTHDXZURNU   \n",
              "4      A06944662TFWOKKV4GJKX   \n",
              "...                      ...   \n",
              "14676          AZWRZZAMX90VT   \n",
              "14677          AZXKAH2DE6C8A   \n",
              "14678          AZXON596A1VXC   \n",
              "14679          AZYXC63SS008M   \n",
              "14680          AZZ5ASC403N74   \n",
              "\n",
              "                                              reviewText  \\\n",
              "0      [It is a good stand by coffee you can count on...   \n",
              "1      [awesome texture for even the gluten eating ea...   \n",
              "2      [I love roasted garlic & sweet bell peppers. Y...   \n",
              "3      [These bars are especially delicious for cocon...   \n",
              "4      [UGH!  My stomach has been really killing me l...   \n",
              "...                                                  ...   \n",
              "14676  [Very nice. Not spicy, not too salty, lots of ...   \n",
              "14677  [Could not imagine having such a rich tasting ...   \n",
              "14678  [I was a bit skeptical when I bought this prod...   \n",
              "14679  [This is just about the healthiest you can get...   \n",
              "14680  [Everybody loves homemade spaghetti sauce, but...   \n",
              "\n",
              "                                                  itemID  \n",
              "0      [B0029XDZIK, B003C4YIFE, B003YUW7EK, B00474OR8...  \n",
              "1      [B000EVE3Y4, B001ACMCNU, B003TO9RSU, B003V8QGA...  \n",
              "2      [B000B6J51I, B000EM6Q34, B000FYXBPW, B003VN74V...  \n",
              "3      [B000HKFF94, B000K8WVYA, B001FA1K2G, B00474VPY...  \n",
              "4      [B000CMD63E, B000CQBZPG, B000GFYRHG, B000GZYAR...  \n",
              "...                                                  ...  \n",
              "14676  [B0007R9L4M, B0007R9L5Q, B000CN7BMA, B000CQ01G...  \n",
              "14677  [B0004N14BC, B0005XOVY8, B000EML7DS, B000EOXQR...  \n",
              "14678  [B00113SKZW, B00113ZTVK, B001EO5RCM, B001EO5S0...  \n",
              "14679  [B000NGNEKY, B0039LVLS2, B0040QCJDG, B0040WCQK...  \n",
              "14680  [B0035N3ADS, B004FEN3GA, B004U49QU2, B00BIEU5P...  \n",
              "\n",
              "[14681 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_df=df[['userID','reviewText',\"itemID\"]].groupby('userID')['reviewText','itemID'].apply(lambda x: pd.Series([list(x['reviewText']),list(x['itemID'])],index=['reviewText', 'itemID'])).reset_index()\n",
        "user_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReAbgOc7q3Tp"
      },
      "source": [
        "**Item Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arvKphT7KCTg"
      },
      "source": [
        "determining all unique items with their reviews and ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "qAjW8mmJq9Cj",
        "outputId": "e03f94a0-8923-417b-c9c0-fd8cd33ea676"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>616719923X</td>\n",
              "      <td>[Just another flavor of Kit Kat but the taste ...</td>\n",
              "      <td>[A1VEELTKS8NLZB, A14R9XMZVJ6INB, A27IQHDZFQFNG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9742356831</td>\n",
              "      <td>[This curry paste makes a delicious curry.  I ...</td>\n",
              "      <td>[A23RYWDS884TUL, A945RBQWGZXCK, A1TCSC0YWT82Q0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B00004S1C5</td>\n",
              "      <td>[These dyes create awesome colors for kids cra...</td>\n",
              "      <td>[A1C8NAHYR6Z10F, A14YSMLYLJEMET, A1358PQON9ZAK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B0000531B7</td>\n",
              "      <td>[I really enjoy these bars as a quick breakfas...</td>\n",
              "      <td>[ATN5X2PM7OB3K, A2BYV7S1QP2YIG, A2TN9C5E4A0I3F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B00005344V</td>\n",
              "      <td>[Traditional Medicinals' \"Breathe Easy\" is an ...</td>\n",
              "      <td>[A3EBHHCZO6V2A4, A1P9UMP1XSE6MI, A2F488C4PLWGE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8708</th>\n",
              "      <td>B00JGPG60I</td>\n",
              "      <td>[We switched to this formula 5 days ago and fo...</td>\n",
              "      <td>[A2D7X9N3IV3S7B, A36NUDST4Y5JBA, A2E4R7YISIM4Q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8709</th>\n",
              "      <td>B00JL6LTMW</td>\n",
              "      <td>[We have enjoyed Larabar's variety of bars for...</td>\n",
              "      <td>[A1QR76SYGTXJN5, A1P2XYD265YE21, A1P9BVW2JB1OV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8710</th>\n",
              "      <td>B00K00H9I6</td>\n",
              "      <td>[This 100% pure Canadian maple syrup is a Grad...</td>\n",
              "      <td>[A23GFTVIETX7DS, A35W3JQYP0M655, A1UQBFCERIP7V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8711</th>\n",
              "      <td>B00KC0LGI8</td>\n",
              "      <td>[I followed the directions on the box exactly ...</td>\n",
              "      <td>[A34U4Y40W1GW9I, A1P9BVW2JB1OVL, A3DS0VAXL90E2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8712</th>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>[Usually the label &amp;#34;gluten free&amp;#34; is a ...</td>\n",
              "      <td>[A3H8PA7AG48K33, A2H2I5FY1PUHP1, A3JH18T58CY65...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8713 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          itemID                                         reviewText  \\\n",
              "0     616719923X  [Just another flavor of Kit Kat but the taste ...   \n",
              "1     9742356831  [This curry paste makes a delicious curry.  I ...   \n",
              "2     B00004S1C5  [These dyes create awesome colors for kids cra...   \n",
              "3     B0000531B7  [I really enjoy these bars as a quick breakfas...   \n",
              "4     B00005344V  [Traditional Medicinals' \"Breathe Easy\" is an ...   \n",
              "...          ...                                                ...   \n",
              "8708  B00JGPG60I  [We switched to this formula 5 days ago and fo...   \n",
              "8709  B00JL6LTMW  [We have enjoyed Larabar's variety of bars for...   \n",
              "8710  B00K00H9I6  [This 100% pure Canadian maple syrup is a Grad...   \n",
              "8711  B00KC0LGI8  [I followed the directions on the box exactly ...   \n",
              "8712  B00KCJRVO2  [Usually the label &#34;gluten free&#34; is a ...   \n",
              "\n",
              "                                                 userID  \n",
              "0     [A1VEELTKS8NLZB, A14R9XMZVJ6INB, A27IQHDZFQFNG...  \n",
              "1     [A23RYWDS884TUL, A945RBQWGZXCK, A1TCSC0YWT82Q0...  \n",
              "2     [A1C8NAHYR6Z10F, A14YSMLYLJEMET, A1358PQON9ZAK...  \n",
              "3     [ATN5X2PM7OB3K, A2BYV7S1QP2YIG, A2TN9C5E4A0I3F...  \n",
              "4     [A3EBHHCZO6V2A4, A1P9UMP1XSE6MI, A2F488C4PLWGE...  \n",
              "...                                                 ...  \n",
              "8708  [A2D7X9N3IV3S7B, A36NUDST4Y5JBA, A2E4R7YISIM4Q...  \n",
              "8709  [A1QR76SYGTXJN5, A1P2XYD265YE21, A1P9BVW2JB1OV...  \n",
              "8710  [A23GFTVIETX7DS, A35W3JQYP0M655, A1UQBFCERIP7V...  \n",
              "8711  [A34U4Y40W1GW9I, A1P9BVW2JB1OVL, A3DS0VAXL90E2...  \n",
              "8712  [A3H8PA7AG48K33, A2H2I5FY1PUHP1, A3JH18T58CY65...  \n",
              "\n",
              "[8713 rows x 3 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item_df=df[['itemID','reviewText','userID']].groupby('itemID')['reviewText','userID'].apply(lambda x: pd.Series([list(x['reviewText']),list(x['userID'])],index=['reviewText', 'userID'])).reset_index()\n",
        "item_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "review num :  151254 user num :  14681 item num :  8713\n"
          ]
        }
      ],
      "source": [
        "print(\"review num : \", df.shape[0] ,\"user num : \" ,user_df.shape[0],\"item num : \",item_df.shape[0] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCekVFHgXtom"
      },
      "source": [
        "##   Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "cZb_XiBoGHSa",
        "outputId": "f1cb72ea-8d50-467a-d412-92d75a9d167e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    151254.000000\n",
              "mean          4.243042\n",
              "std           1.090003\n",
              "min           1.000000\n",
              "25%           4.000000\n",
              "50%           5.000000\n",
              "75%           5.000000\n",
              "max           5.000000\n",
              "Name: rating, dtype: float64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.groupby('rating').size().plot(kind=\"bar\");\n",
        "df['rating'].describe()\n",
        "#histogram of ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGLa04uYQRt"
      },
      "source": [
        "## Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0QEq-vnYohN",
        "outputId": "183d2ce2-65c2-49c9-ca8c-7f216083e4bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count     151254\n",
              "unique    151199\n",
              "top             \n",
              "freq          22\n",
              "Name: reviewText, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['reviewText'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "OLw7n7EcbEKV",
        "outputId": "ffd1376f-19a1-42f2-a991-e490d04d84d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    151254.000000\n",
              "mean        509.002142\n",
              "std         524.745639\n",
              "min           0.000000\n",
              "25%         191.000000\n",
              "50%         353.000000\n",
              "75%         644.000000\n",
              "max       29569.000000\n",
              "Name: reviewText, dtype: float64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# review length\n",
        "rv_le=df['reviewText'].apply(lambda x:len(x) )\n",
        "rv_le.plot(kind='hist',bins=2000,figsize=(24, 8),xlabel=\"length of reviews\")\n",
        "rv_le.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTgNznNQ8aR1",
        "outputId": "3c1809ac-2fc3-4d67-ce83-7253c8687332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean of reviews per user: 10.302704175464887\n",
            "mean of words per review: 509.00214209211\n",
            "mean of words per user: 5244.098494652953\n"
          ]
        }
      ],
      "source": [
        "sum=0\n",
        "sum2=0\n",
        "for x in user_df['reviewText']:\n",
        "  sum+=len(x)\n",
        "  for y in x:\n",
        "   sum2 +=len(y)\n",
        "\n",
        "r_mean=sum/len(user_df['reviewText'])\n",
        "w_mean=sum2/(r_mean*len(user_df['reviewText']))\n",
        "print('mean of reviews per user:', r_mean)\n",
        "print('mean of words per review:', w_mean)\n",
        "print('mean of words per user:',r_mean * w_mean)\n",
        "# plot for reviews per user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    8713.000000\n",
              "mean       17.359578\n",
              "std        33.915980\n",
              "min         5.000000\n",
              "25%         6.000000\n",
              "50%         8.000000\n",
              "75%        14.000000\n",
              "max       742.000000\n",
              "Name: reviewText, dtype: float64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "rv_le=item_df['reviewText'].apply(lambda x:len(x) )\n",
        "rv_le.plot(kind='hist',bins=2000,figsize=(24, 8),xlabel=\"length of reviews\")\n",
        "rv_le.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    14681.000000\n",
              "mean        10.302704\n",
              "std         10.581392\n",
              "min          5.000000\n",
              "25%          5.000000\n",
              "50%          7.000000\n",
              "75%         11.000000\n",
              "max        204.000000\n",
              "Name: reviewText, dtype: float64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "rv_le=user_df['reviewText'].apply(lambda x:len(x) )\n",
        "rv_le.plot(kind='hist',bins=2000,figsize=(24, 8),xlabel=\"length of reviews\")\n",
        "rv_le.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nje_ix7gAaf3",
        "outputId": "c3260e88-aa4f-46f3-aa38-85cbb25e0219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean of reviews per item: 17.359577642603007\n",
            "mean of words per review: 509.00214209211\n",
            "mean of words per item: 8836.062205899232\n"
          ]
        }
      ],
      "source": [
        "sum=0\n",
        "sum2=0\n",
        "for x in item_df['reviewText']:\n",
        "  sum+=len(x)\n",
        "  for y in x:\n",
        "   sum2 +=len(y)\n",
        "\n",
        "r_mean=sum/len(item_df['reviewText'])\n",
        "w_mean=sum2/(r_mean*len(item_df['reviewText']))\n",
        "print('mean of reviews per item:', r_mean)\n",
        "print('mean of words per review:', w_mean)\n",
        "print('mean of words per item:',r_mean * w_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "if os.path.exists(\"train_df.csv\") & os.path.exists(\"test_df.csv\"):\n",
        "        train_df = pd.read_csv('train_df.csv')\n",
        "        test_df = pd.read_csv('test_df.csv')\n",
        "\n",
        "else:\n",
        "    current_fold=10\n",
        "    kfold = KFold(10)\n",
        "    random_iterator=kfold.split(df)\n",
        "    for i in range(current_fold):\n",
        "      train_index, test_index = next(random_iterator, None)\n",
        "      print(train_index,len(train_index))\n",
        "      train_df, test_df =df.iloc[train_index], df.iloc[test_index]\n",
        "    train_df.to_csv('train_df.csv')\n",
        "    test_df.to_csv('test_df.csv')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A1VEELTKS8NLZB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A14R9XMZVJ6INB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I bought this on impulse and it comes from Jap...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A27IQHDZFQFNGG</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Really good. Great gift for any fan of green t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A31QY5TASILE89</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I had never had it before, was curious to see ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>A2LWK003FFMCI5</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I've been looking forward to trying these afte...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136124</th>\n",
              "      <td>136124</td>\n",
              "      <td>A74CGCGJ11Y23</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>I've made rice pilaf from scratch. I've also t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136125</th>\n",
              "      <td>136125</td>\n",
              "      <td>A36MP37DITBU6F</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>This is a slightly mild flavored rice pilaf. t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136126</th>\n",
              "      <td>136126</td>\n",
              "      <td>A1JBBR4MNGQ70G</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>I added a package of Albacore tuna to this mix...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136127</th>\n",
              "      <td>136127</td>\n",
              "      <td>A2P739KOM4U5JB</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>I am happy to report that Side Mates were grea...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136128</th>\n",
              "      <td>136128</td>\n",
              "      <td>AT53ZTTO707MB</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>This was a nice combo of rice, pasta and herbs...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136129 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0          userID      itemID  \\\n",
              "0                0  A1VEELTKS8NLZB  616719923X   \n",
              "1                1  A14R9XMZVJ6INB  616719923X   \n",
              "2                2  A27IQHDZFQFNGG  616719923X   \n",
              "3                3  A31QY5TASILE89  616719923X   \n",
              "4                4  A2LWK003FFMCI5  616719923X   \n",
              "...            ...             ...         ...   \n",
              "136124      136124   A74CGCGJ11Y23  B009M516NE   \n",
              "136125      136125  A36MP37DITBU6F  B009M516NE   \n",
              "136126      136126  A1JBBR4MNGQ70G  B009M516NE   \n",
              "136127      136127  A2P739KOM4U5JB  B009M516NE   \n",
              "136128      136128   AT53ZTTO707MB  B009M516NE   \n",
              "\n",
              "                                               reviewText  rating  \n",
              "0       Just another flavor of Kit Kat but the taste i...     4.0  \n",
              "1       I bought this on impulse and it comes from Jap...     3.0  \n",
              "2       Really good. Great gift for any fan of green t...     4.0  \n",
              "3       I had never had it before, was curious to see ...     5.0  \n",
              "4       I've been looking forward to trying these afte...     4.0  \n",
              "...                                                   ...     ...  \n",
              "136124  I've made rice pilaf from scratch. I've also t...     4.0  \n",
              "136125  This is a slightly mild flavored rice pilaf. t...     4.0  \n",
              "136126  I added a package of Albacore tuna to this mix...     3.0  \n",
              "136127  I am happy to report that Side Mates were grea...     4.0  \n",
              "136128  This was a nice combo of rice, pasta and herbs...     3.0  \n",
              "\n",
              "[136129 rows x 5 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvMysaUvxxU3"
      },
      "source": [
        "# **Embedding Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WovD0fA5q-J6"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "embedding_dim=300\n",
        "min_frequent_word_num=5\n",
        "max_vocab_size=30000\n",
        "sequence_length=250\n",
        "document_length=40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  text = tf.strings.strip(text)\n",
        "  text= tf.strings.reduce_join( tf.strings.split(text)[:,:sequence_length-2],axis=-1,separator=' ')\n",
        "  return  text.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.device('/CPU:0'):\n",
        "    user_corpus =list(map(tf_lower_and_split_punct,user_df['reviewText'])) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_word2vec_model():\n",
        "    if os.path.exists(\"word2vec.wordvectors\"):\n",
        "        print(\"loaded from word2vec.wordvectors\")\n",
        "        return KeyedVectors.load(\"word2vec.wordvectors\",mmap='r')\n",
        "    else:\n",
        "        # downloading google news word2vec model\n",
        "        if not os.path.exists(\"word2vec_google.bin\"):\n",
        "            downloaded_model = api.load('word2vec-google-news-300')\n",
        "            downloaded_model.save_word2vec_format('word2vec_google.bin',binary=True)\n",
        "            del downloaded_model\n",
        "        # loading google news word2vec model\n",
        "        google_word2vec = KeyedVectors.load_word2vec_format(\"word2vec_google.bin\", binary=True)\n",
        "\n",
        "       # tokenizing the whole reviews in text_corpus\n",
        "        text_corpus=[]\n",
        "        for i,doc in enumerate(user_corpus):    # iterate through each sentence in the reviews\n",
        "            for rv in doc:\n",
        "                for sen in sent_tokenize(rv.decode(\"utf-8\")):\n",
        "                    temp = []\n",
        "                    # tokenize the sentence into words          \n",
        "                    for j in word_tokenize(sen):\n",
        "                        temp.append(j.lower())\n",
        "                    text_corpus.append(temp)\n",
        "                    del temp\n",
        "\n",
        "\n",
        "        # creating a new word2vec model and initializing it from pretrained google_word2vec\n",
        "        word2vec_model=Word2Vec( text_corpus,max_final_vocab=max_vocab_size,min_count=min_frequent_word_num ,vector_size= embedding_dim,window = 5,workers=16, sg=1,epochs=1)\n",
        "        word2vec_model.build_vocab(text_corpus)\n",
        "\n",
        "        word2vec_model.build_vocab([google_word2vec.index_to_key],update=True)\n",
        "        word2vec_model.wv.vectors_lockf = np.ones(len(word2vec_model.wv))\n",
        "        word2vec_model.wv.intersect_word2vec_format(\"word2vec_google.bin\",binary=True,lockf=1.0)\n",
        "        \n",
        "        # fine tuning the model and saving it\n",
        "        word2vec_model.train(text_corpus, epochs=5, total_examples=word2vec_model.corpus_count)\n",
        "        word2vec_model.wv.save(\"word2vec.wordvectors\")\n",
        "        \n",
        "        del google_word2vec\n",
        "        del text_corpus[:]\n",
        "        gc.collect()\n",
        "  \n",
        "        return word2vec_model.wv\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded from word2vec.wordvectors\n",
            "embedding matrix shape : ( 22284  , 300 )\n"
          ]
        }
      ],
      "source": [
        "# loading the embedding lookup matrix shape=( 30k ,300 ) approximately\n",
        "embedding_matrix = load_word2vec_model() \n",
        "print( \"embedding matrix shape : (\",len(embedding_matrix.index_to_key),\" ,\",embedding_matrix.vector_size,\")\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(22288, 300)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# adding 4 vectors for start end unknow and null tokens\n",
        "special_token_embedding = np.random.rand(4,embedding_matrix.vector_size)\n",
        "full_embedding_matrix = np.concatenate((special_token_embedding,embedding_matrix.vectors))\n",
        "full_embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# example\n",
        "# embedding_matrix['keep']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVT3Ur54LsIz"
      },
      "source": [
        "# **Text Vectorization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of batches in train data 4254\n",
            "number of batches in test data 472\n"
          ]
        }
      ],
      "source": [
        "# hyperparameter\n",
        "\n",
        "batch_size = 32 # for encoder model\n",
        "batch_size_test = 32 # for encoder model\n",
        "num_batches = int(train_df.shape[0]/batch_size)\n",
        "num_batches_test = int(test_df.shape[0]/batch_size_test)\n",
        "print(\"number of batches in train data\",num_batches)\n",
        "print(\"number of batches in test data\",num_batches_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tf_lower_and_split_punct_enc(text):\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  text = tf.strings.strip(text)\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "def tf_lower_and_split_punct_decin(text):\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  text = tf.strings.strip(text)\n",
        "  text = tf.strings.join(['[START]', text], separator=' ') \n",
        "  return text\n",
        "\n",
        "\n",
        "def tf_lower_and_split_punct_decout(text):\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  text = tf.strings.strip(text)\n",
        "  text = tf.strings.join([ text, '[END]'], separator=' ')\n",
        "  return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vectorization layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4QVJNF8EGGe"
      },
      "source": [
        "- The conversion of tokens to ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "enc_input_processor = tf.keras.layers.TextVectorization( max_tokens = max_vocab_size,\n",
        "                                                     standardize = tf_lower_and_split_punct_enc,\n",
        "                                                     output_sequence_length = sequence_length,  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "enc_input_processor.set_vocabulary(['','[UNK]','[START]','[END]'] +  embedding_matrix.index_to_key )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "333\n",
            "involved\n"
          ]
        }
      ],
      "source": [
        "print(enc_input_processor.get_vocabulary().index('come'))\n",
        "print(enc_input_processor.get_vocabulary()[3351])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"These candies are very good. They have a nice cherry flavor with just a little bit of sour thrown in. Most sour candies made these days make your eyes water and your mouth pucker. Not these gummi's, they have just enough of a sour taste to make them interesting but the sour taste is very very mild.My order came in great condition and very fresh.\", 'Decided to try these out since I loved the non sour versions of this gummy. Great in their own right but I have to say that the originals are the best. But these have a very unique taste. And not really that sour, just a little bitterness to them but nothing to take away from the over all taste.', 'received very fast and item  was in tact. If for personal use over a long period suggest divide it up and put into airtight storage bags or a sealer to keep soft and tasty!', \"These Haribo sour cherries are vibrantly colored and look like a red cherry on a green stem with a green leaf attached.  Each piece is over an inch long.  They are very cute!Unfortunately, they are sugary sweet and not sour to me at all.  They taste just like those cherry flavored cough drops that come in the red and white box and have no medicinal purposes whatsoever!If you like the flavor of artificial cherries, these are good.  They smell good too.  If you are looking for candies for a kids birthday party, these will definitely be a hit!  If you need a sugary pick-me-up, grab a few and you're set.  But if you really want something more sour, try another kind of Haribo candy.Added thought:  these would be beautiful cake decorations!\", 'I love Haribo products and have for nearly  years. It is nice to be able to buy them bulk on Amazon. These are delicious but since taste is subjective, try some for yourself.']\n",
            "tf.Tensor(\n",
            "[[   2   33  918 ...    0    0    0]\n",
            " [   2  485   10 ...    0    0    0]\n",
            " [   2  523   42 ...    0    0    0]\n",
            " [   2   33 2820 ...    0    0    0]\n",
            " [   2    7   61 ...    0    0    0]], shape=(5, 250), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "print(item_df['reviewText'][1000])\n",
        "print(enc_input_processor(  item_df['reviewText'][1000]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Forming Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert string id to int id\n",
        "user_to_row = {}\n",
        "item_to_column = {}\n",
        "\n",
        "for i, user_id in enumerate(np.unique(df['userID'])):\n",
        "    user_to_row[user_id] = i\n",
        "\n",
        "for j, item_id in enumerate(np.unique(df['itemID'].tolist())):\n",
        "    item_to_column[item_id] = j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "item_df[\"userID\"]=item_df[\"userID\"].apply(lambda x :[user_to_row[el] for el in x ])\n",
        "user_df[\"itemID\"]=user_df[\"itemID\"].apply(lambda x :[item_to_column[el] for el in x ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds_seq = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "       [user_to_row[dp] for dp in train_df['userID']],\n",
        "       [item_to_column[dp] for dp in train_df['itemID']]\n",
        "     \n",
        "    )\n",
        ").shuffle(131072).batch(batch_size,drop_remainder=True)\n",
        "\n",
        "test_ds_seq = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "       [user_to_row[dp] for dp in test_df['userID']],\n",
        "       [item_to_column[dp] for dp in test_df['itemID']]\n",
        "     \n",
        "    )\n",
        ").shuffle(16384).batch(batch_size,drop_remainder=True)\n",
        "\n",
        "\n",
        "train_ds_pmf = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "       [user_to_row[dp] for dp in train_df['userID']],\n",
        "       [item_to_column[dp] for dp in train_df['itemID']],\n",
        "       tf.cast(train_df['rating'],dtype=tf.float16)\n",
        "    )\n",
        ").shuffle(131072).batch(1024)\n",
        "test_ds_pmf = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "      [user_to_row[dp] for dp in test_df['userID']],\n",
        "      [item_to_column[dp] for dp in test_df['itemID']],\n",
        "      tf.cast(test_df['rating'],dtype=tf.float16)\n",
        "    )\n",
        ").shuffle(16384).batch(256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train and test data number :  136129  ,  15125\n"
          ]
        }
      ],
      "source": [
        "train_data_num=train_df.shape[0]\n",
        "test_data_num=test_df.shape[0]\n",
        "print(\"train and test data number : \",train_data_num,\" , \",test_data_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV4PGxjttli6"
      },
      "source": [
        "# **User and Item Documents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BwcnBKDxVMk"
      },
      "source": [
        "**User Documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_doc = list( map(enc_input_processor,[doc[:document_length] for doc in user_df['reviewText']]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWDCul-D_N99"
      },
      "source": [
        "**Item Documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "phoN10nsXZGc"
      },
      "outputs": [],
      "source": [
        "item_doc = list( map(enc_input_processor,[doc[:document_length] for doc in item_df['reviewText']]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# log files for training and test\n",
        "train_log_dir = 'logs/'  + '/train'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "adv_train_log_dir = 'logs/'  + '/adv_train'\n",
        "adv_train_summary_writer = tf.summary.create_file_writer(adv_train_log_dir)\n",
        "test_log_dir = 'logs/'  + '/test'\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "graph_log_dir = 'logs/graph/'  \n",
        "graph_summary_writer = tf.summary.create_file_writer(graph_log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RegularizationLoss(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='perplexity',**kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.regularizationloss=self.add_weight(name='rg',initializer='zeros')\n",
        "\n",
        "    def update_state(self, loss):\n",
        "        self.regularizationloss= loss\n",
        "\n",
        "    def result(self):\n",
        "        return self.regularizationloss\n",
        "\n",
        "\n",
        "class MSE(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='MSE',**kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mse=self.add_weight(name='mse',initializer='zeros')\n",
        "\n",
        "    def update_state(self,mse):\n",
        "        self.mse =  mse\n",
        "\n",
        "    def result(self):\n",
        "        return self.mse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_reg_loss = RegularizationLoss(name=\"reg\")\n",
        "train_mse = MSE(name='trian mse')\n",
        "test_mse = MSE(name='test mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Context-aware Matrix Factorization for Rating Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hyperparameters\n",
        "num_users=len(user_to_row)\n",
        "num_items=len(item_to_column)\n",
        "mean_inv = np.float32( train_df['rating'].mean())\n",
        "feature_num=128 # number of topics\n",
        "units=int(feature_num/2 )# gru units"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uKWBtzhmMA5"
      },
      "source": [
        "## **PMF (Probabilistic Matrix Factorization)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "5JAoyyjOnJis"
      },
      "outputs": [],
      "source": [
        "class PMF():\n",
        "    def __init__(self, num_feat=16, epsilon=1, _lambda=0.2, momentum=0.8,  batch_size=1024,num_item=9000,num_user=15000,mean_inv=3.00000):\n",
        "        self.num_feat = num_feat  # Number of latent features,\n",
        "        self.epsilon = epsilon  # learning rate,\n",
        "        self._lambda = _lambda  # L2 regularization,\n",
        "        self.momentum = momentum  # momentum of the gradient,\n",
        "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
        "        self.num_item=num_item\n",
        "        self.num_user=num_user\n",
        "        self.V =  0.1 * np.random.randn(self.num_item, self.num_feat).astype(np.float64)  # Item feature vectors\n",
        "        self.U =  0.1 * np.random.randn(self.num_user, self.num_feat).astype(np.float64)  # User feature vectors\n",
        "        self.V_inc = np.zeros((self.num_item, self.num_feat),dtype=np.float64)\n",
        "        self.U_inc = np.zeros((self.num_user, self.num_feat),dtype=np.float64)\n",
        "        self.mean_inv= mean_inv  \n",
        "        \n",
        "        self.user_textual_features = np.zeros(shape=(num_users, feature_num),dtype=np.float32 )\n",
        "        self.item_textual_features =  np.zeros(shape=(num_items, feature_num),dtype=np.float32)\n",
        "        self.user_recommender_features =  np.zeros(shape=(num_users, feature_num),dtype=np.float64)\n",
        "        self.item_recommender_features =  np.zeros(shape=(num_items, feature_num),dtype=np.float64)\n",
        "    \n",
        "    def update_textual_features(self, user_textual_features , item_textual_features ):\n",
        "        self.user_textual_features = user_textual_features\n",
        "        self.item_textual_features = item_textual_features \n",
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "            \n",
        "            for batch_UserID,batch_ItemID, batch_rating  in train_ds_pmf:\n",
        "                  \n",
        "                # Compute Objective Function             \n",
        "                pred_out = np.sum(np.multiply(self.U[batch_UserID, :],\n",
        "                                              self.V[batch_ItemID, :]),\n",
        "                                  axis=1)  # mean_inv subtracted # np.multiply\n",
        "                \n",
        "                rawErr = pred_out - batch_rating.numpy() + self.mean_inv\n",
        "\n",
        "                # Compute gradients\n",
        "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.V[batch_ItemID, :]) \\\n",
        "                       + self._lambda * (self.U[batch_UserID, :] - self.user_textual_features[batch_UserID,:] )\n",
        "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.U[batch_UserID, :]) \\\n",
        "                       + self._lambda * (self.V[batch_ItemID, :] - self.item_textual_features[batch_ItemID,:] ) \n",
        "                       # np.newaxis :increase the dimension\n",
        "               \n",
        "                dw_Item = np.zeros((self.num_item, self.num_feat))\n",
        "                dw_User = np.zeros((self.num_user, self.num_feat))\n",
        "                \n",
        "                # loop to aggreate the gradients of the same element\n",
        "                for i in range(batch_UserID.shape[0]):\n",
        "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
        "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
        "\n",
        "                # Update with momentum\n",
        "              \n",
        "                self.V_inc = self.momentum * self.V_inc + self.epsilon * dw_Item / self.batch_size\n",
        "                self.U_inc = self.momentum * self.U_inc + self.epsilon * dw_User / self.batch_size\n",
        "                \n",
        "                self.V = self.V - self.V_inc\n",
        "                self.U = self.U - self.U_inc\n",
        "            \n",
        "                # Compute Objective Function after\n",
        "            self.evaluate()\n",
        "\n",
        "            return  tf.Variable(self.U) , tf.Variable(self.V)\n",
        "    \n",
        "    def evaluate(self):\n",
        "            rawErr= []\n",
        "            for batch_UserID,batch_ItemID, batch_rating  in train_ds_pmf:\n",
        "                        \n",
        "                pred_out = np.sum(np.multiply(self.U[batch_UserID, :],\n",
        "                                        self.V[batch_ItemID, :]),\n",
        "                                axis=1)  # mean_inv subtracted\n",
        "                rawErr.append(pred_out - batch_rating.numpy() + self.mean_inv)\n",
        "\n",
        "            obj = np.linalg.norm([item for sublist in rawErr for item in sublist]) ** 2 \n",
        "                   # + 0.5 * self._lambda * (np.linalg.norm(self.U - self.user_textual_features) ** 2 + np.linalg.norm(self.V - self.item_textual_features) ** 2)\n",
        "\n",
        "            train_mse.update_state(obj / train_data_num)\n",
        "           # Compute test error\n",
        "            rawErr= []\n",
        "            for batch_UserID,batch_ItemID, batch_rating  in test_ds_pmf:\n",
        "                pred_out = np.sum(np.multiply(self.U[batch_UserID, :],\n",
        "                                        self.V[batch_ItemID, :]),\n",
        "                                axis=1)  # mean_inv subtracted\n",
        "\n",
        "                rawErr.append(pred_out - batch_rating.numpy() + self.mean_inv)\n",
        "\n",
        "            test_mse.update_state(np.linalg.norm([item for sublist in rawErr for item in sublist])**2 / test_data_num)\n",
        "            # Print info\n",
        "            print('\\nTraining mse: %f, Test mse %f' % (train_mse.result(), test_mse.result()))\n",
        "\n",
        "\n",
        "    def predict(self, invID):\n",
        "        return np.dot(self.V, self.U[int(invID), :]) + self.mean_inv  \n",
        "\n",
        "    def topK(self, user_number, k=10):\n",
        "        inv_lst = np.random.choice(range(0,self.num_user),user_number).astype('int32')\n",
        "        pred = {}\n",
        "        for inv in inv_lst:\n",
        "            if pred.get(inv, None) is None:\n",
        "                pred[inv] = np.argsort(self.predict(inv))[-k:]  \n",
        "  \n",
        "        for _,user_id in enumerate(pred):\n",
        "           print(\"user id:\",user_id,\"recommended items\",pred[user_id])\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8UVYfYjX9YW"
      },
      "source": [
        "# **Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TwRd0VNHkMf0"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self,vocab_size, embedding_dim, enc_units):\n",
        "    super().__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding_dim=embedding_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding( self.vocab_size, self.embedding_dim, embeddings_initializer=keras.initializers.Constant(full_embedding_matrix),trainable=False)\n",
        "    self.gru= tf.keras.layers.Bidirectional(tf.keras.layers.GRU(  self.enc_units,return_state=True,  recurrent_initializer='glorot_uniform' ))\n",
        "\n",
        "\n",
        "  def call(self, reviews, state=None):\n",
        "    vectors = self.embedding(reviews)\n",
        "    _,encoder_forward_state,encoder_backward_state  = self.gru(vectors, initial_state=state)\n",
        " \n",
        "    return  tf.concat([ encoder_forward_state, encoder_backward_state],-1)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Topic Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Z3NlswFZRbub"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(tf.keras.Model): \n",
        "    def __init__(self,num_topic,num_item ,num_user, units ,embedding_dim,vocab_size ,sequence_length, num_batches,num_batches_test, batch_size, use_tf_function=False):\n",
        "        super().__init__()\n",
        "        self.num_batches_test = num_batches_test\n",
        "        self.num_batches = num_batches # train batch number\n",
        "        self.batch_size = batch_size\n",
        "        self.num_topic = num_topic\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.units = units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.sequence_length = sequence_length\n",
        "        self.num_item = num_item\n",
        "        self.num_user = num_user\n",
        "        self.alpha = 10.0\n",
        "        self.user_encoder = Encoder(vocab_size= self.vocab_size,  embedding_dim= self.embedding_dim, enc_units= self.units)\n",
        "        self.item_encoder = Encoder(vocab_size= self.vocab_size,  embedding_dim= self.embedding_dim, enc_units= self.units)     \n",
        "        self.optimizer_gn = tf.optimizers.Adam(1e-4)\n",
        "\n",
        "        self.user_textual_features = np.zeros(shape=(num_users, feature_num),dtype=np.float32 )\n",
        "        self.item_textual_features =  np.zeros(shape=(num_items, feature_num),dtype=np.float32)\n",
        "        self.user_recommender_features =  np.zeros(shape=(num_users, feature_num),dtype=np.float64)\n",
        "        self.item_recommender_features =  np.zeros(shape=(num_items, feature_num),dtype=np.float64)\n",
        "\n",
        "    \n",
        "    \n",
        "    def update_recommender_features(self,user_recommender_features , item_recommender_features):\n",
        "         self.user_recommender_features = user_recommender_features\n",
        "         self.item_recommender_features = item_recommender_features\n",
        "\n",
        "    def generate_textual_features(self):\n",
        "          for start_index in range(0, self.num_user, self.batch_size):\n",
        "            end_index = min(start_index + self.batch_size, self.num_user)                           \n",
        "            batch_userID = np.arange(start_index, end_index)\n",
        "\n",
        "            # fetch a batch of user doc\n",
        "            batch_userdoc_flattend=[]\n",
        "            userdoc_slice_idx=[0]\n",
        "            for doc_id in batch_userID:\n",
        "              userdoc_slice_idx.append(userdoc_slice_idx[-1] + user_doc[doc_id].shape[0])\n",
        "              batch_userdoc_flattend = np.append(batch_userdoc_flattend,user_doc[doc_id])\n",
        "            batch_userdoc = tf.reshape(tf.convert_to_tensor( batch_userdoc_flattend,dtype=tf.int32),[userdoc_slice_idx[-1],self.sequence_length])\n",
        "\n",
        "            user_enc_state = self.user_encoder(batch_userdoc) # user vector representations      \n",
        "            user_context_vector = tf.stack([ tf.reduce_mean(user_enc_state[ userdoc_slice_idx[sl_num] : userdoc_slice_idx[sl_num+1] ],0) for  sl_num in range(len(batch_userID))])\n",
        "            \n",
        "            self.user_textual_features[batch_userID]=user_context_vector.numpy()\n",
        "            \n",
        "          for start_index in range(0, self.num_item, self.batch_size):\n",
        "            end_index = min(start_index + self.batch_size, self.num_item)                           \n",
        "            batch_itemID = np.arange(start_index, end_index)\n",
        "\n",
        "            # fetch a batch of item doc\n",
        "            batch_itemdoc_flattend=[]\n",
        "            itemdoc_slice_idx=[0]\n",
        "            for doc_id in batch_itemID:\n",
        "              itemdoc_slice_idx.append(itemdoc_slice_idx[-1] + item_doc[doc_id].shape[0])\n",
        "              batch_itemdoc_flattend = np.append(batch_itemdoc_flattend,item_doc[doc_id])\n",
        "            batch_itemdoc = tf.reshape(tf.convert_to_tensor( batch_itemdoc_flattend,dtype=tf.int32),[itemdoc_slice_idx[-1],self.sequence_length])\n",
        "            \n",
        "            item_enc_state = self.item_encoder(batch_itemdoc) # item vector representations\n",
        "            item_context_vector = tf.stack([ tf.reduce_mean(item_enc_state[ itemdoc_slice_idx[sl_num] : itemdoc_slice_idx[sl_num+1] ],0) for  sl_num in range(len(batch_itemID))])\n",
        "            \n",
        "            self.item_textual_features[batch_itemID]=item_context_vector.numpy()\n",
        "           \n",
        "            return tf.Variable(self.user_textual_features) , tf.Variable(self.item_textual_features)\n",
        "\n",
        "    def train(self):\n",
        "          total_gen_loss=0\n",
        "          for t_step in range(self.num_batches):\n",
        " \n",
        "            (batch_userID,batch_itemID) = next(iter(train_ds_seq))\n",
        "            # fetch a batch of user doc\n",
        "            batch_userdoc_flattend=[]\n",
        "            userdoc_slice_idx=[0]\n",
        "            for doc_id in batch_userID:\n",
        "              userdoc_slice_idx.append(userdoc_slice_idx[-1] + user_doc[doc_id].shape[0])\n",
        "              batch_userdoc_flattend = np.append(batch_userdoc_flattend,user_doc[doc_id])\n",
        "            batch_userdoc = tf.reshape(tf.convert_to_tensor( batch_userdoc_flattend,dtype=tf.int32),[userdoc_slice_idx[-1],self.sequence_length])\n",
        "\n",
        "            # fetch a batch of item doc\n",
        "            batch_itemdoc_flattend=[]\n",
        "            itemdoc_slice_idx=[0]\n",
        "            for doc_id in batch_itemID:\n",
        "              itemdoc_slice_idx.append(itemdoc_slice_idx[-1] + item_doc[doc_id].shape[0])\n",
        "              batch_itemdoc_flattend = np.append(batch_itemdoc_flattend,item_doc[doc_id])\n",
        "            batch_itemdoc = tf.reshape(tf.convert_to_tensor( batch_itemdoc_flattend,dtype=tf.int32),[itemdoc_slice_idx[-1],self.sequence_length])\n",
        "            \n",
        "            with tf.GradientTape() as tape :              \n",
        "              user_enc_state = self.user_encoder(batch_userdoc) # user vector representations      \n",
        "                \n",
        "              user_context_vector = tf.stack([ tf.reduce_mean(user_enc_state[ userdoc_slice_idx[sl_num] : userdoc_slice_idx[sl_num+1] ],0) for  sl_num in range(self.batch_size)])\n",
        "              # regularization \n",
        "              user_regularization_loss = self.alpha * tf.norm(self.user_recommender_features[batch_userID.numpy()] - user_context_vector) **2\n",
        "            grad_enc = tape.gradient(user_regularization_loss,self.user_encoder.trainable_variables)\n",
        "            self.optimizer_gn.apply_gradients(zip( grad_enc, self.user_encoder.trainable_variables ))            \n",
        "            \n",
        "            total_gen_loss += user_regularization_loss\n",
        "            # total_regularization_loss += regularization_loss\n",
        "            if t_step % 10 == 0:\n",
        "              print(\"batch number: \",t_step,\"\\t encoder loss: \", user_regularization_loss)\n",
        "    \n",
        "          train_reg_loss.update_state(total_gen_loss / self.num_batches)\n",
        "\n",
        "    def test(self,num_steps):\n",
        "        total_loss=0\n",
        "        for step in range(num_steps):\n",
        "            #(batch_userID,batch_itemID ,_,_) = next(iter(test_ds_seq))\n",
        "            batch_userID = np.random.choice(range(0,self.num_user),self.batch_size).astype('int32')\n",
        "            batch_itemID = np.random.choice(range(0,self.num_item),self.batch_size).astype('int32') \n",
        "            context_vector = tf.concat([self.user_textual_features[batch_userID],self.item_textual_features[batch_itemID]],1)                    \n",
        "            predicted_samples,dec_prob = self.generate_sample(context_vector)\n",
        "            loss = self.loss_gn(predicted_samples ,tf.transpose( tf.stack(dec_prob), [1,0,2])  )\n",
        "            total_loss += loss\n",
        "            if step % 4 == 0:\n",
        "              print(\"batch number: \",step, \"\\tgen loss: \",loss.numpy())\n",
        "\n",
        "        test_plx_gen.update_state(total_loss / num_steps)\n",
        "  \n",
        "  \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Ploting Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-fcb201fdc5d6177\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-fcb201fdc5d6177\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir logs --bind_all\n",
        "# deactive tracking protection of the page if you get 403 error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3YKdf1-uW8Q"
      },
      "source": [
        "# **Multi-Task Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "khZxlR9oRxVe"
      },
      "outputs": [],
      "source": [
        "class MultiTaskModel(tf.keras.Model):\n",
        "      def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pmf_model = PMF(num_feat=feature_num,num_item= num_items ,num_user= num_users, mean_inv=mean_inv)\n",
        "        self.seq2seq_model = Seq2Seq(num_topic=feature_num,num_item= num_items ,num_user= num_users,units=units, embedding_dim= embedding_dim,vocab_size=full_embedding_matrix.shape[0],sequence_length=sequence_length, num_batches= num_batches,num_batches_test=num_batches_test,batch_size= batch_size)      \n",
        "        self.user_textual_features = tf.Variable( np.zeros(shape=(num_users, feature_num),dtype=np.float32 ))\n",
        "        self.item_textual_features = tf.Variable( np.zeros(shape=(num_items, feature_num),dtype=np.float32))\n",
        "        self.user_recommender_features = tf.Variable( np.zeros(shape=(num_users, feature_num),dtype=np.float64))\n",
        "        self.item_recommender_features = tf.Variable( np.zeros(shape=(num_items, feature_num),dtype=np.float64))\n",
        "      \n",
        "      def predict(self,user_number=5):\n",
        "         prediction = self.pmf_model.topK(user_number)\n",
        "         self.generate_explanation(prediction)\n",
        "      \n",
        "      def generate_explanation(self,prediction):\n",
        "        for target_user_id in prediction:\n",
        "          for item_id in prediction[target_user_id]:\n",
        "            review_user_pair = item_df[[\"reviewText\",\"userID\"]].loc[item_id]\n",
        "            similar_user_idx = self.most_similar_users(target_user_id, review_user_pair[\"userID\"]) \n",
        "            relevant_reviews = [el[1]  for el in np.array(list( zip(review_user_pair[\"userID\"],review_user_pair[\"reviewText\"]))) if int(el[0]) in similar_user_idx]\n",
        "            positive_explanation = []\n",
        "            sentiment_scores = []\n",
        "            for rv in relevant_reviews:\n",
        "              sum_rv = summarize(rv, ratio=0.5)\n",
        "              sentences = nltk.sent_tokenize(sum_rv)\n",
        "              analyzer  = SentimentIntensityAnalyzer()\n",
        "              for sentence in sentences:\n",
        "                vs = analyzer.polarity_scores(sentence)\n",
        "                if vs[\"compound\"] > 0.1 :\n",
        "                   positive_explanation.append(sentence)\n",
        "                   sentiment_scores.append(float(vs[\"compound\"]))\n",
        " \n",
        "            exp_score_pair = list( zip(positive_explanation,sentiment_scores))\n",
        "            exp_score_pair.sort( reverse=True,key=lambda x: x[1])\n",
        "            print(\"\\n\\n\",\"user id :\",target_user_id,\"recommended item id :\",item_id,\"\\n explanation :\")\n",
        "            for el in exp_score_pair[:4]:\n",
        "              print(\" - \",el[0])\n",
        "\n",
        "            \n",
        "      def most_similar_users(self,target_user_id, user_idx,top_k=5):\n",
        "         cosine_loss = tf.keras.losses.CosineSimilarity(axis=1,  reduction=tf.keras.losses.Reduction.NONE)\n",
        "         a=tf.tile(tf.expand_dims( self.user_textual_features[target_user_id],0),[len(user_idx),1])\n",
        "         b=tf.gather(self.user_textual_features , user_idx)\n",
        "         cosine_similarity = cosine_loss( a, b ).numpy()\n",
        "         most_similar_idx =  cosine_similarity.argsort()[-top_k:][::-1]\n",
        "         return np.array(user_idx)[most_similar_idx]\n",
        "\n",
        "\n",
        "         \n",
        "      def train(self,n_epochs):    \n",
        "          ckpt.restore(manager.latest_checkpoint)\n",
        "          if manager.latest_checkpoint:\n",
        "            print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "          else:\n",
        "            print(\"Initializing from scratch.\")\n",
        "          #tf.profiler.experimental.start('logs')\n",
        "          for epoch in range(n_epochs):\n",
        "              if epoch == 0:\n",
        "                 self.pmf_model.U = self.user_recommender_features.numpy()\n",
        "                 self.pmf_model.V = self.item_recommender_features.numpy()\n",
        "              \n",
        "              print(\"\\n\\nepoch : \", int(ckpt.step))\n",
        "              self.user_textual_features,self.item_textual_features = self.seq2seq_model.generate_textual_features()\n",
        "              self.pmf_model.update_textual_features( self.user_textual_features.numpy(),self.item_textual_features.numpy() )\n",
        "              \n",
        "              print(\"********************************************* PMF Model Training Turn *********************************************\")\n",
        "              self.user_recommender_features , self.item_recommender_features = self.pmf_model.train()\n",
        "              print(\"\\n\\n******************************************* Seq2Seq Model Training Turn *******************************************\")                                         \n",
        "              self.seq2seq_model.update_recommender_features(self.user_recommender_features.numpy() , self.item_recommender_features.numpy())\n",
        "              self.seq2seq_model.train()\n",
        "\n",
        "              with train_summary_writer.as_default():\n",
        "                  tf.summary.scalar('perplexity for Seq2Seq model', train_reg_loss.result(), step=int(ckpt.step))\n",
        "                  tf.summary.scalar('MSE for PMF model',train_mse.result(),step=int(ckpt.step))\n",
        "  \n",
        "              with test_summary_writer.as_default():\n",
        "                  tf.summary.scalar('MSE for PMF model',test_mse.result(),step=int(ckpt.step))\n",
        "\n",
        "              ckpt.step.assign_add(1)\n",
        "              if int(ckpt.step) % 2 ==0:\n",
        "                save_path = manager.save()\n",
        "                print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.step), save_path))\n",
        "            \n",
        "          #tf.profiler.experimental.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrzxSK6IUr6O",
        "outputId": "212b1776-5de7-4896-f09a-4ea54c2405df"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "gc.collect(0)\n",
        "gc.collect(1)\n",
        "gc.collect(2)\n",
        "\n",
        "# creating an instance of Multi_Task Model\n",
        "mt_model = MultiTaskModel()\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(0), optimizer=tf.keras.optimizers.Adam(), net=mt_model)\n",
        "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing from scratch.\n",
            "\n",
            "\n",
            "epoch :  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-25 11:40:22.225135: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************************************* PMF Model Training Turn *********************************************\n",
            "\n",
            "Training mse: 1.189452, Test mse 1.167727\n",
            "\n",
            "\n",
            "******************************************* Seq2Seq Model Training Turn *******************************************\n",
            "batch number:  0 \tgen loss:  tf.Tensor(6392.4077, shape=(), dtype=float32)\n",
            "batch number:  10 \tgen loss:  tf.Tensor(4077.625, shape=(), dtype=float32)\n",
            "batch number:  20 \tgen loss:  tf.Tensor(2667.0166, shape=(), dtype=float32)\n",
            "batch number:  30 \tgen loss:  tf.Tensor(1711.8024, shape=(), dtype=float32)\n",
            "batch number:  40 \tgen loss:  tf.Tensor(1036.2202, shape=(), dtype=float32)\n",
            "batch number:  50 \tgen loss:  tf.Tensor(628.6305, shape=(), dtype=float32)\n",
            "batch number:  60 \tgen loss:  tf.Tensor(292.53845, shape=(), dtype=float32)\n",
            "batch number:  70 \tgen loss:  tf.Tensor(149.38475, shape=(), dtype=float32)\n",
            "batch number:  80 \tgen loss:  tf.Tensor(69.40379, shape=(), dtype=float32)\n",
            "batch number:  90 \tgen loss:  tf.Tensor(36.20422, shape=(), dtype=float32)\n",
            "batch number:  100 \tgen loss:  tf.Tensor(41.659744, shape=(), dtype=float32)\n",
            "batch number:  110 \tgen loss:  tf.Tensor(26.52893, shape=(), dtype=float32)\n",
            "batch number:  120 \tgen loss:  tf.Tensor(21.044914, shape=(), dtype=float32)\n",
            "batch number:  130 \tgen loss:  tf.Tensor(23.627995, shape=(), dtype=float32)\n",
            "batch number:  140 \tgen loss:  tf.Tensor(19.412628, shape=(), dtype=float32)\n",
            "batch number:  150 \tgen loss:  tf.Tensor(13.5063505, shape=(), dtype=float32)\n",
            "batch number:  160 \tgen loss:  tf.Tensor(20.199245, shape=(), dtype=float32)\n",
            "batch number:  170 \tgen loss:  tf.Tensor(27.414547, shape=(), dtype=float32)\n",
            "batch number:  180 \tgen loss:  tf.Tensor(26.408873, shape=(), dtype=float32)\n",
            "batch number:  190 \tgen loss:  tf.Tensor(23.253534, shape=(), dtype=float32)\n",
            "batch number:  200 \tgen loss:  tf.Tensor(30.02676, shape=(), dtype=float32)\n",
            "batch number:  210 \tgen loss:  tf.Tensor(21.56802, shape=(), dtype=float32)\n",
            "batch number:  220 \tgen loss:  tf.Tensor(17.920807, shape=(), dtype=float32)\n",
            "batch number:  230 \tgen loss:  tf.Tensor(15.695797, shape=(), dtype=float32)\n",
            "batch number:  240 \tgen loss:  tf.Tensor(14.607729, shape=(), dtype=float32)\n",
            "batch number:  250 \tgen loss:  tf.Tensor(18.729574, shape=(), dtype=float32)\n",
            "batch number:  260 \tgen loss:  tf.Tensor(20.64165, shape=(), dtype=float32)\n",
            "batch number:  270 \tgen loss:  tf.Tensor(11.512016, shape=(), dtype=float32)\n",
            "batch number:  280 \tgen loss:  tf.Tensor(30.54288, shape=(), dtype=float32)\n",
            "batch number:  290 \tgen loss:  tf.Tensor(15.747281, shape=(), dtype=float32)\n",
            "batch number:  300 \tgen loss:  tf.Tensor(11.174658, shape=(), dtype=float32)\n",
            "batch number:  310 \tgen loss:  tf.Tensor(11.7757845, shape=(), dtype=float32)\n",
            "batch number:  320 \tgen loss:  tf.Tensor(11.303314, shape=(), dtype=float32)\n",
            "batch number:  330 \tgen loss:  tf.Tensor(17.72348, shape=(), dtype=float32)\n",
            "batch number:  340 \tgen loss:  tf.Tensor(16.819494, shape=(), dtype=float32)\n",
            "batch number:  350 \tgen loss:  tf.Tensor(14.226642, shape=(), dtype=float32)\n",
            "batch number:  360 \tgen loss:  tf.Tensor(13.046135, shape=(), dtype=float32)\n",
            "batch number:  370 \tgen loss:  tf.Tensor(16.112309, shape=(), dtype=float32)\n",
            "batch number:  380 \tgen loss:  tf.Tensor(16.514265, shape=(), dtype=float32)\n",
            "batch number:  390 \tgen loss:  tf.Tensor(10.317531, shape=(), dtype=float32)\n",
            "batch number:  400 \tgen loss:  tf.Tensor(10.825987, shape=(), dtype=float32)\n",
            "batch number:  410 \tgen loss:  tf.Tensor(11.052273, shape=(), dtype=float32)\n",
            "batch number:  420 \tgen loss:  tf.Tensor(14.093542, shape=(), dtype=float32)\n",
            "batch number:  430 \tgen loss:  tf.Tensor(11.786261, shape=(), dtype=float32)\n",
            "batch number:  440 \tgen loss:  tf.Tensor(12.241484, shape=(), dtype=float32)\n",
            "batch number:  450 \tgen loss:  tf.Tensor(11.286773, shape=(), dtype=float32)\n",
            "batch number:  460 \tgen loss:  tf.Tensor(10.138859, shape=(), dtype=float32)\n",
            "batch number:  470 \tgen loss:  tf.Tensor(15.575124, shape=(), dtype=float32)\n",
            "batch number:  480 \tgen loss:  tf.Tensor(10.000606, shape=(), dtype=float32)\n",
            "batch number:  490 \tgen loss:  tf.Tensor(12.520273, shape=(), dtype=float32)\n",
            "batch number:  500 \tgen loss:  tf.Tensor(9.732813, shape=(), dtype=float32)\n",
            "batch number:  510 \tgen loss:  tf.Tensor(9.243357, shape=(), dtype=float32)\n",
            "batch number:  520 \tgen loss:  tf.Tensor(9.864325, shape=(), dtype=float32)\n",
            "batch number:  530 \tgen loss:  tf.Tensor(10.158098, shape=(), dtype=float32)\n",
            "batch number:  540 \tgen loss:  tf.Tensor(11.132604, shape=(), dtype=float32)\n",
            "batch number:  550 \tgen loss:  tf.Tensor(8.520281, shape=(), dtype=float32)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-25 11:43:14.029414: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 266.02MiB (rounded to 278946304)requested by op CudnnRNNBackprop\n",
            "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
            "Current allocation summary follows.\n",
            "Current allocation summary follows.\n",
            "2022-12-25 11:43:14.029543: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
            "2022-12-25 11:43:14.029570: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 50, Chunks in use: 50. 12.5KiB allocated for chunks. 12.5KiB in use in bin. 3.2KiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029584: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029599: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 11, Chunks in use: 11. 16.2KiB allocated for chunks. 16.2KiB in use in bin. 16.0KiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029609: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029619: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029630: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 1, Chunks in use: 0. 13.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029643: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 9, Chunks in use: 8. 173.2KiB allocated for chunks. 157.2KiB in use in bin. 141.5KiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029656: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 10, Chunks in use: 8. 503.2KiB allocated for chunks. 402.5KiB in use in bin. 384.0KiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029668: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 10, Chunks in use: 8. 762.0KiB allocated for chunks. 604.5KiB in use in bin. 546.0KiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029680: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 16, Chunks in use: 16. 3.34MiB allocated for chunks. 3.34MiB in use in bin. 3.23MiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029691: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 7, Chunks in use: 7. 2.16MiB allocated for chunks. 2.16MiB in use in bin. 1.83MiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029704: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 724.8KiB allocated for chunks. 724.8KiB in use in bin. 724.6KiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029714: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029724: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029737: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 2. 16.02MiB allocated for chunks. 11.42MiB in use in bin. 11.42MiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029749: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 4, Chunks in use: 2. 45.18MiB allocated for chunks. 22.85MiB in use in bin. 22.85MiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029762: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 1. 41.51MiB allocated for chunks. 25.51MiB in use in bin. 25.51MiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029774: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 4, Chunks in use: 4. 188.94MiB allocated for chunks. 188.94MiB in use in bin. 161.37MiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029785: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029831: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 3, Chunks in use: 2. 635.29MiB allocated for chunks. 424.58MiB in use in bin. 424.58MiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029854: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 4. 1.08GiB allocated for chunks. 1.08GiB in use in bin. 1.00GiB client-requested in use in bin.\n",
            "2022-12-25 11:43:14.029910: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 266.02MiB was 256.00MiB, Chunk State: \n",
            "2022-12-25 11:43:14.029926: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 1073741824\n",
            "2022-12-25 11:43:14.029951: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6b94000000 of size 284928256 next 152\n",
            "2022-12-25 11:43:14.029970: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6ba4fba900 of size 222600192 next 153\n",
            "2022-12-25 11:43:14.029982: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6bb2404500 of size 284928256 next 74\n",
            "2022-12-25 11:43:14.029993: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6bc33bee00 of size 281285120 next 18446744073709551615\n",
            "2022-12-25 11:43:14.030000: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 536870912\n",
            "2022-12-25 11:43:14.030004: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c32000000 of size 222600192 next 150\n",
            "2022-12-25 11:43:14.030008: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c3f449c00 of size 314270720 next 18446744073709551615\n",
            "2022-12-25 11:43:14.030011: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 268435456\n",
            "2022-12-25 11:43:14.030015: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c7a000000 of size 47488000 next 109\n",
            "2022-12-25 11:43:14.030019: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6c7cd49c00 of size 220947456 next 18446744073709551615\n",
            "2022-12-25 11:43:14.030022: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 134217728\n",
            "2022-12-25 11:43:14.030026: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c8a000000 of size 15033344 next 87\n",
            "2022-12-25 11:43:14.030030: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c8ae56400 of size 8922112 next 65\n",
            "2022-12-25 11:43:14.030034: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c8b6d8800 of size 47488000 next 174\n",
            "2022-12-25 11:43:14.030038: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c8e422400 of size 62774272 next 18446744073709551615\n",
            "2022-12-25 11:43:14.030041: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 67108864\n",
            "2022-12-25 11:43:14.030045: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c92000000 of size 26745600 next 27\n",
            "2022-12-25 11:43:14.030051: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c93981b00 of size 40363264 next 18446744073709551615\n",
            "2022-12-25 11:43:14.030055: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 33554432\n",
            "2022-12-25 11:43:14.030059: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6c96000000 of size 15033344 next 21\n",
            "2022-12-25 11:43:14.030063: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c96e56400 of size 7516672 next 44\n",
            "2022-12-25 11:43:14.030066: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c97581600 of size 4461056 next 53\n",
            "2022-12-25 11:43:14.030070: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c979c2800 of size 230400 next 151\n",
            "2022-12-25 11:43:14.030074: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c979fac00 of size 230400 next 123\n",
            "2022-12-25 11:43:14.030078: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c97a33000 of size 76800 next 110\n",
            "2022-12-25 11:43:14.030084: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c97a45c00 of size 76800 next 47\n",
            "2022-12-25 11:43:14.030088: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c97a58800 of size 16384 next 144\n",
            "2022-12-25 11:43:14.030092: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c97a5c800 of size 16384 next 57\n",
            "2022-12-25 11:43:14.030096: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c97a60800 of size 16384 next 81\n",
            "2022-12-25 11:43:14.030100: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c97a64800 of size 189952 next 111\n",
            "2022-12-25 11:43:14.030104: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c97a92e00 of size 189952 next 163\n",
            "2022-12-25 11:43:14.030108: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c97ac1400 of size 303616 next 169\n",
            "2022-12-25 11:43:14.030114: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6c97b0b600 of size 379904 next 136\n",
            "2022-12-25 11:43:14.030118: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6c97b68200 of size 4816384 next 18446744073709551615\n",
            "2022-12-25 11:43:14.030122: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 16777216\n",
            "2022-12-25 11:43:14.030126: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6cce000000 of size 16777216 next 18446744073709551615\n",
            "2022-12-25 11:43:14.030130: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 2097152\n",
            "2022-12-25 11:43:14.030135: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01000000 of size 1280 next 1\n",
            "2022-12-25 11:43:14.030140: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01000500 of size 256 next 2\n",
            "2022-12-25 11:43:14.030144: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01000600 of size 256 next 3\n",
            "2022-12-25 11:43:14.030148: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01000700 of size 256 next 4\n",
            "2022-12-25 11:43:14.030152: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01000800 of size 256 next 9\n",
            "2022-12-25 11:43:14.030156: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01000900 of size 256 next 6\n",
            "2022-12-25 11:43:14.030160: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01000a00 of size 178432 next 7\n",
            "2022-12-25 11:43:14.030164: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102c300 of size 256 next 5\n",
            "2022-12-25 11:43:14.030168: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102c400 of size 256 next 8\n",
            "2022-12-25 11:43:14.030172: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102c500 of size 256 next 14\n",
            "2022-12-25 11:43:14.030177: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102c600 of size 256 next 15\n",
            "2022-12-25 11:43:14.030181: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102c700 of size 256 next 16\n",
            "2022-12-25 11:43:14.030185: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102c800 of size 256 next 23\n",
            "2022-12-25 11:43:14.030189: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102c900 of size 256 next 22\n",
            "2022-12-25 11:43:14.030193: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102ca00 of size 256 next 17\n",
            "2022-12-25 11:43:14.030197: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102cb00 of size 256 next 19\n",
            "2022-12-25 11:43:14.030201: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102cc00 of size 256 next 30\n",
            "2022-12-25 11:43:14.030205: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102cd00 of size 256 next 31\n",
            "2022-12-25 11:43:14.030210: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102ce00 of size 256 next 32\n",
            "2022-12-25 11:43:14.030214: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102cf00 of size 256 next 35\n",
            "2022-12-25 11:43:14.030219: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102d000 of size 1536 next 36\n",
            "2022-12-25 11:43:14.030223: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102d600 of size 1536 next 40\n",
            "2022-12-25 11:43:14.030227: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102dc00 of size 1536 next 58\n",
            "2022-12-25 11:43:14.030232: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102e200 of size 1536 next 52\n",
            "2022-12-25 11:43:14.030236: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0102e800 of size 49152 next 88\n",
            "2022-12-25 11:43:14.030241: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0103a800 of size 63488 next 10\n",
            "2022-12-25 11:43:14.030245: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0104a000 of size 30464 next 13\n",
            "2022-12-25 11:43:14.030252: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01051700 of size 76800 next 114\n",
            "2022-12-25 11:43:14.030256: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01064300 of size 252416 next 28\n",
            "2022-12-25 11:43:14.030260: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d010a1d00 of size 49152 next 38\n",
            "2022-12-25 11:43:14.030264: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d010add00 of size 411648 next 34\n",
            "2022-12-25 11:43:14.030269: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01112500 of size 230400 next 33\n",
            "2022-12-25 11:43:14.030274: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0114a900 of size 49152 next 42\n",
            "2022-12-25 11:43:14.030278: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6d01156900 of size 78336 next 80\n",
            "2022-12-25 11:43:14.030282: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01169b00 of size 49152 next 93\n",
            "2022-12-25 11:43:14.030287: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01175b00 of size 53760 next 39\n",
            "2022-12-25 11:43:14.030291: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01182d00 of size 230400 next 37\n",
            "2022-12-25 11:43:14.030297: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011bb100 of size 256 next 173\n",
            "2022-12-25 11:43:14.030302: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011bb200 of size 256 next 161\n",
            "2022-12-25 11:43:14.030306: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011bb300 of size 256 next 126\n",
            "2022-12-25 11:43:14.030310: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011bb400 of size 76800 next 107\n",
            "2022-12-25 11:43:14.030314: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6d011ce000 of size 16384 next 113\n",
            "2022-12-25 11:43:14.030318: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011d2000 of size 256 next 106\n",
            "2022-12-25 11:43:14.030322: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6d011d2100 of size 60160 next 140\n",
            "2022-12-25 11:43:14.030325: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011e0c00 of size 81408 next 129\n",
            "2022-12-25 11:43:14.030329: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f4a00 of size 256 next 130\n",
            "2022-12-25 11:43:14.030333: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f4b00 of size 256 next 131\n",
            "2022-12-25 11:43:14.030337: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f4c00 of size 256 next 132\n",
            "2022-12-25 11:43:14.030341: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f4d00 of size 256 next 133\n",
            "2022-12-25 11:43:14.030345: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f4e00 of size 256 next 134\n",
            "2022-12-25 11:43:14.030349: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f4f00 of size 256 next 135\n",
            "2022-12-25 11:43:14.030354: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f5000 of size 256 next 96\n",
            "2022-12-25 11:43:14.030358: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f5100 of size 256 next 103\n",
            "2022-12-25 11:43:14.030362: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f5200 of size 256 next 101\n",
            "2022-12-25 11:43:14.030367: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f5300 of size 256 next 91\n",
            "2022-12-25 11:43:14.030373: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f5400 of size 256 next 108\n",
            "2022-12-25 11:43:14.030377: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f5500 of size 256 next 167\n",
            "2022-12-25 11:43:14.030382: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f5600 of size 256 next 82\n",
            "2022-12-25 11:43:14.030386: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d011f5700 of size 256 next 104\n",
            "2022-12-25 11:43:14.030391: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6d011f5800 of size 43008 next 18446744073709551615\n",
            "2022-12-25 11:43:14.030396: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 4194304\n",
            "2022-12-25 11:43:14.030401: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01400000 of size 272384 next 12\n",
            "2022-12-25 11:43:14.030406: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01442800 of size 256 next 72\n",
            "2022-12-25 11:43:14.030410: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01442900 of size 256 next 86\n",
            "2022-12-25 11:43:14.030414: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01442a00 of size 16384 next 143\n",
            "2022-12-25 11:43:14.030418: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01446a00 of size 32256 next 59\n",
            "2022-12-25 11:43:14.030423: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0144e800 of size 49152 next 75\n",
            "2022-12-25 11:43:14.030427: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0145a800 of size 49152 next 49\n",
            "2022-12-25 11:43:14.030432: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6d01466800 of size 82944 next 51\n",
            "2022-12-25 11:43:14.030436: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0147ac00 of size 230400 next 43\n",
            "2022-12-25 11:43:14.030441: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014b3000 of size 204288 next 76\n",
            "2022-12-25 11:43:14.030446: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e4e00 of size 256 next 125\n",
            "2022-12-25 11:43:14.030450: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e4f00 of size 256 next 98\n",
            "2022-12-25 11:43:14.030454: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e5000 of size 256 next 66\n",
            "2022-12-25 11:43:14.030460: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e5100 of size 256 next 115\n",
            "2022-12-25 11:43:14.030464: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e5200 of size 256 next 83\n",
            "2022-12-25 11:43:14.030468: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e5300 of size 1536 next 55\n",
            "2022-12-25 11:43:14.030473: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e5900 of size 1536 next 89\n",
            "2022-12-25 11:43:14.030478: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e5f00 of size 1536 next 85\n",
            "2022-12-25 11:43:14.030482: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e6500 of size 1536 next 48\n",
            "2022-12-25 11:43:14.030487: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e6b00 of size 256 next 73\n",
            "2022-12-25 11:43:14.030492: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e6c00 of size 256 next 117\n",
            "2022-12-25 11:43:14.030497: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e6d00 of size 256 next 142\n",
            "2022-12-25 11:43:14.030501: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e6e00 of size 256 next 69\n",
            "2022-12-25 11:43:14.030506: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e6f00 of size 256 next 70\n",
            "2022-12-25 11:43:14.030510: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e7000 of size 256 next 60\n",
            "2022-12-25 11:43:14.030514: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e7100 of size 256 next 54\n",
            "2022-12-25 11:43:14.030518: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e7200 of size 1536 next 67\n",
            "2022-12-25 11:43:14.030523: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014e7800 of size 1536 next 164\n",
            "2022-12-25 11:43:14.030527: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6d014e7e00 of size 13824 next 62\n",
            "2022-12-25 11:43:14.030532: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d014eb400 of size 230400 next 46\n",
            "2022-12-25 11:43:14.030536: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01523800 of size 281088 next 147\n",
            "2022-12-25 11:43:14.030542: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01568200 of size 331008 next 18\n",
            "2022-12-25 11:43:14.030548: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d015b8f00 of size 230400 next 71\n",
            "2022-12-25 11:43:14.030553: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d015f1300 of size 230400 next 90\n",
            "2022-12-25 11:43:14.030558: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01629700 of size 230400 next 84\n",
            "2022-12-25 11:43:14.030563: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01661b00 of size 742144 next 100\n",
            "2022-12-25 11:43:14.030567: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01716e00 of size 76800 next 119\n",
            "2022-12-25 11:43:14.030572: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01729a00 of size 76800 next 158\n",
            "2022-12-25 11:43:14.030577: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0173c600 of size 76800 next 122\n",
            "2022-12-25 11:43:14.030582: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0174f200 of size 16384 next 61\n",
            "2022-12-25 11:43:14.030586: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01753200 of size 16384 next 165\n",
            "2022-12-25 11:43:14.030590: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d01757200 of size 281088 next 171\n",
            "2022-12-25 11:43:14.030595: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d0179bc00 of size 189952 next 157\n",
            "2022-12-25 11:43:14.030599: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d017ca200 of size 220672 next 18446744073709551615\n",
            "2022-12-25 11:43:14.030602: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 8388608\n",
            "2022-12-25 11:43:14.030606: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6d01800000 of size 8388608 next 18446744073709551615\n",
            "2022-12-25 11:43:14.030610: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
            "2022-12-25 11:43:14.030616: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 50 Chunks of size 256 totalling 12.5KiB\n",
            "2022-12-25 11:43:14.030622: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
            "2022-12-25 11:43:14.030627: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 10 Chunks of size 1536 totalling 15.0KiB\n",
            "2022-12-25 11:43:14.030632: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 6 Chunks of size 16384 totalling 96.0KiB\n",
            "2022-12-25 11:43:14.030637: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 30464 totalling 29.8KiB\n",
            "2022-12-25 11:43:14.030643: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 32256 totalling 31.5KiB\n",
            "2022-12-25 11:43:14.030647: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 6 Chunks of size 49152 totalling 288.0KiB\n",
            "2022-12-25 11:43:14.030653: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 53760 totalling 52.5KiB\n",
            "2022-12-25 11:43:14.030658: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 63488 totalling 62.0KiB\n",
            "2022-12-25 11:43:14.030662: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 7 Chunks of size 76800 totalling 525.0KiB\n",
            "2022-12-25 11:43:14.030667: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 81408 totalling 79.5KiB\n",
            "2022-12-25 11:43:14.030672: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 178432 totalling 174.2KiB\n",
            "2022-12-25 11:43:14.030677: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 189952 totalling 556.5KiB\n",
            "2022-12-25 11:43:14.030682: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 204288 totalling 199.5KiB\n",
            "2022-12-25 11:43:14.030686: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 220672 totalling 215.5KiB\n",
            "2022-12-25 11:43:14.030691: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 9 Chunks of size 230400 totalling 1.98MiB\n",
            "2022-12-25 11:43:14.030696: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 252416 totalling 246.5KiB\n",
            "2022-12-25 11:43:14.030702: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 272384 totalling 266.0KiB\n",
            "2022-12-25 11:43:14.030707: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 281088 totalling 549.0KiB\n",
            "2022-12-25 11:43:14.030711: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 303616 totalling 296.5KiB\n",
            "2022-12-25 11:43:14.030716: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 331008 totalling 323.2KiB\n",
            "2022-12-25 11:43:14.030720: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 379904 totalling 371.0KiB\n",
            "2022-12-25 11:43:14.030725: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 411648 totalling 402.0KiB\n",
            "2022-12-25 11:43:14.030730: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 742144 totalling 724.8KiB\n",
            "2022-12-25 11:43:14.030735: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4461056 totalling 4.25MiB\n",
            "2022-12-25 11:43:14.030740: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 7516672 totalling 7.17MiB\n",
            "2022-12-25 11:43:14.030744: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 8922112 totalling 8.51MiB\n",
            "2022-12-25 11:43:14.030749: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 15033344 totalling 14.34MiB\n",
            "2022-12-25 11:43:14.030753: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 26745600 totalling 25.51MiB\n",
            "2022-12-25 11:43:14.030758: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 40363264 totalling 38.49MiB\n",
            "2022-12-25 11:43:14.030763: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 47488000 totalling 90.58MiB\n",
            "2022-12-25 11:43:14.030768: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 62774272 totalling 59.87MiB\n",
            "2022-12-25 11:43:14.030774: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 222600192 totalling 424.58MiB\n",
            "2022-12-25 11:43:14.030779: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 281285120 totalling 268.25MiB\n",
            "2022-12-25 11:43:14.030786: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 284928256 totalling 543.46MiB\n",
            "2022-12-25 11:43:14.030791: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 314270720 totalling 299.71MiB\n",
            "2022-12-25 11:43:14.030797: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 1.75GiB\n",
            "2022-12-25 11:43:14.030801: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 2145386496 memory_limit_: 2236547072 available bytes: 91160576 curr_region_allocation_bytes_: 2147483648\n",
            "2022-12-25 11:43:14.030811: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
            "Limit:                      2236547072\n",
            "InUse:                      1879128832\n",
            "MaxInUse:                   2100716288\n",
            "NumAllocs:                      604636\n",
            "MaxAllocSize:                377405184\n",
            "Reserved:                            0\n",
            "PeakReserved:                        0\n",
            "LargestFreeBlock:                    0\n",
            "\n",
            "2022-12-25 11:43:14.030823: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ************************************************xx************************x***_________*************\n",
            "2022-12-25 11:43:14.030859: E tensorflow/stream_executor/dnn.cc:868] OOM when allocating tensor with shape[278946112] and type uint8 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
            "2022-12-25 11:43:14.030907: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at cudnn_rnn_ops.cc:1969 : INTERNAL: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 300, 64, 1, 250, 742, 0] \n"
          ]
        },
        {
          "ename": "InternalError",
          "evalue": "Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 300, 64, 1, 250, 742, 0]  [Op:CudnnRNNBackprop]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_45477/561035493.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_45477/517301750.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n******************************************* Seq2Seq Model Training Turn *******************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2seq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_recommender_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_recommender_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_recommender_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2seq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m               \u001b[0;32mwith\u001b[0m \u001b[0mtrain_summary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_45477/3384447004.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m               \u001b[0;31m# regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m               \u001b[0muser_regularization_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_recommender_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_userID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0muser_context_vector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mgrad_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_regularization_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_gn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mgrad_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/ops/cudnn_rnn_grad.py\u001b[0m in \u001b[0;36m_cudnn_rnn_backward\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mrnn_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rnn_mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0minput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m       direction=op.get_attr(\"direction\"))\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn_backprop\u001b[0;34m(input, input_h, input_c, params, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space, rnn_mode, input_mode, direction, dropout, seed, seed2, name)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7164\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 300, 64, 1, 250, 742, 0]  [Op:CudnnRNNBackprop]"
          ]
        }
      ],
      "source": [
        "mt_model.train(n_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xniWi24qcZsb"
      },
      "source": [
        "# **Model Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user id: 9405 recommended items [5319 6236 2753  593 3371 5324 6863 6256 4660 6608]\n",
            "user id: 5259 recommended items [5319 6236 2753  593 3371 5324 6863 6256 4660 6608]\n",
            "user id: 4762 recommended items [5319 6236 2753  593 3371 6863 5324 6256 4660 6608]\n",
            "user id: 190 recommended items [5319 6236 2753  593 3371 5324 6863 6256 4660 6608]\n",
            "user id: 2021 recommended items [5319 6236 2753  593 3371 5324 6863 6256 4660 6608]\n",
            "\n",
            "\n",
            " user id : 9405 recommended item id : 5319 \n",
            " explanation :\n",
            " -  Good Housekeeping said that one (Barilla Plus) tastes like \"white pasta,\" while the other (which like Barilla Whole Grain Thin Spaghetti is made with 51% whole wheat) \"earned points for its deliciously chewy texture and mildly nutty flavor.\n",
            " -  Barilla cooks much better and is ready to serve in minutes.Because this is a whole grain product, the goodness of the germ, endosperm, and fiber are all present.\n",
            " -  It offers a better alternative to traditional pastas which often take out some of the healthiest parts of the grain in order to make the taste more ordinary and acceptable.This spaghetti product cooks easily and the final product is stringy and ready for sauce or seasoning without clumping.\n",
            " -  Barilla Whole Grain Thin Spaghetti is a great tasting product that prepares fast and easily.\n",
            "\n",
            "\n",
            " user id : 9405 recommended item id : 6236 \n",
            " explanation :\n",
            " -  Thus, the great benefit of the HONEY MAIN FRESH STACKS product is not really \"freshness,\" but ease in packing an individual serving for school or trips.Now for the good part.\n",
            " -  Yet another reason for this new packaging is likely to prevent breakage, that might occur with the traditional rectangular crackers, during transportation.But a more likely reason is to allow people to take individual servings with them, perhaps on trips, to school, or to work, with the confidence that the crackers will be kept safe, secure, and intact.\n",
            " -  This will definitely allow those of us without lots of graham cracker eaters in the house to have fresh ones on hand.The perfect size for smores, these are packed as squares, or half the large rectangles we are used to.\n",
            " -  And Nabisco's Honey Maid is - after much testing of other manufacturers' competing product - easily the best graham cracker out there.\n",
            "\n",
            "\n",
            " user id : 9405 recommended item id : 2753 \n",
            " explanation :\n",
            " -  It probably doesn't matter; just a personal quirk, I guess.Anyway, this is good stuff: the taste is nice -- very good for sweetich things like carrots or plums, for example (I always have a bowl of very lightly steamed carrots around, and I snack on them, taking one and dipping it into CO, which is good for two reasons: first, it tastes great, and second, carotene is fat-soluble so you need to combine carrots with some sort of fat or it won't be used by the body well).All in all, there isn't much to say -- CO is CO is CO; this kind is no different from other types I've tried.\n",
            " -  ), even when close to 75 degrees - and for that reason, it is much better for use in baking, where a hard fat works much better than a soft one.But another characteristic of coconut oil that I love is its flavor and aroma - when you open the jar and stick your nose down in it, you are enveloped in the beauty of the coconut's best element, its aroma - its almost frightening how beautiful that smell is.\n",
            " -  Healthy fats, like this oil, will not affect insulin and give us much more stable energy that last longer in the body.5) Tastes great.\n",
            " -  This one is easily the best so far.The aroma is wonderful and the texture is much fuller than the other brands.\n",
            "\n",
            "\n",
            " user id : 9405 recommended item id : 593 \n",
            " explanation :\n",
            " -  Dark Magic DECAF is wonderfully strong and bold- quite similar to the regular, which happens to be my favorite kcup of all.\n",
            " -  A light blend should be FULL of a light flavor, and personally I didn't find this to be the case with GM's breakfast blend.Still, reading through the reviews it seems like many people enjoy the taste, and I won't fault them for it - coffee (like wine, cheese and most of gastronomy) is so subjective sometimes that there's no way I'm going to not recommend at least giving this a try to people who typically enjoy light blends.\n",
            " -  I received a couple of these Breakfast Blend K-Cups in a variety pack and decided to give them a shot - I've always been pretty pleased with Green Mountain coffee (several of their other blends are on my Wish List) and with them sitting there in the box  I figured \"why not?\"\n",
            " -  I was underwhelmed at most of them, but there were a few that were good enough to convince me that my Keurig COULD make an exceptional cup of coffee.\n",
            "\n",
            "\n",
            " user id : 9405 recommended item id : 3371 \n",
            " explanation :\n",
            " -  I would recommend this coconut oil to everyone because of it's many health benefits and versatility of use (You can spread it on your toast it tastes so great or cook with it as you would any cooking oil, as well as use it on your skin.\n",
            " -  I combine it with pure organic cold pressed olive oil- my hair loves it.The quality and texture are great.I like the containers- they're plastic jars which makes storing them a breeze.I also use this on my skin sometimes, and it works GREAT.\n",
            " -  I'm so glad I did, too, because this stuff is great and for a number of things, some of which caught me off guard.- Cooking -I enjoy cooking with it now and then, especially with my quick-fix quesadillas when I don't have time to cook anything else.\n",
            " -  The smell is strong, if you like coconut you'll love this.\n",
            "\n",
            "\n",
            " user id : 9405 recommended item id : 5324 \n",
            " explanation :\n",
            " -  Then when cool enough, I added the remaining ingredients.My nutritious lunch was discussed by a nutritionist, praised by the hikers, and enjoyed by all.\n",
            " -  I love this shape more than spaghetti or regular size penne for any dish that has a rich red sauce.\n",
            " -  I prepared some cooked to al dente perfection with a homemade sauce consisting of Parmesan cheese, milk, butter (unsalted), garlic, basil (dried from last year's garden) and fresh ground black pepper (I try to watch my sodium intake so I let everyone add salt at the table if they want), and it was a hit.Barilla is my go-to pasta brand when I shop for groceries.\n",
            " -  I chose to use the Mezze Penne n.369 to make a turkey pasta salad as part of a nutritious, energy boosting lunch for my charity hike team.Barilla, established in Parma Italy during 1877, is Italy's #1 brand of pasta.\n",
            "\n",
            "\n",
            " user id : 9405 recommended item id : 6863 \n",
            " explanation :\n",
            " -  I am VERY appreciative of the fact that Baby Gourmet makes a tasty product even adults can enjoy and further, that their label is ACCURATE by weight.As has been pointed out by fellow Vine Program member, Work of Life,  Happy Baby Organic Baby Food isn't quite so honest about their content.\n",
            " -  Intended for babies age 6 months and younger, this food offers infants the same natural food goodness that adults have been enjoying thanks to the organic/green movement.This baby food is loaded with vitamins for an infant's good health and well- being.\n",
            " -  Like  Vine Member, Work To Life, I highly rcommend the following book:Feeding Baby Green: The Earth Friendly Program for Healthy, Safe Nutrition During Pregnancy, Childhood, and Beyondand I also recommend the follow-up book by the same author,Raising Baby Green: The Earth-Friendly Guide to Pregnancy, Childbirth, and Baby Careto any of you who are striving to raise healthy children in a grocery store amnnd marketing world full of deceptive labels and advertising.\n",
            " -  In way way, that is good news, however, since that means the product gives your child 4% of the needed proten for the RDA (hopefully the rest is coming from breast milk or an approriate formula) 50% of the RDA for Vitamin A, 140% of the RDA for Vitamin C, no calicium to speak of even though spinach is supposed to be a good source (tells ya something) and 4 % of of the RDA for Iron.The biggest concern I have with this product is the packaging since that big plastic cap looks like a toy and if your child is clever enough to get it off the pouch once emptied, you know it's going stright into their mouth where it woull be chewed upon and possible choked upon.\n",
            "\n",
            "\n",
            " user id : 9405 recommended item id : 6256 \n",
            " explanation :\n",
            " -  This is truly a pasta that you can time to yield a perfect al dente firmness, which is important in soups because they tend to get reheated a number of times.In the customer-supplied images at the top of this page I've provided a photo of how my own recipe for Pasta e fagioli turns out.\n",
            " -  There are lots of great sounding recipes for ditalini to be found online that I'm eager to try (with names like Garlic and Leek Ditalini, Chicken Rollatini with Ditalini, and Lentils with Sopressata and Ditalini) and one can of course use their imagination.Barilla is my go-to pasta brand when I shop for groceries.\n",
            " -  There's a nice recipe on the box, Barilla Ditilini Soup with Barley and Potato that sounds scrumptious and has a prep time of only 15 minutes, 45 minutes to the table.This Barilla Ditalini will cook will cook up \"Al Dente\" in 10 - 11 minutes or if you want more tender pasta, cook an additional minute or two.\n",
            " -  Ditalini is a new pasta shape to me, and because I love to make big batches of homemade soup I was eager to try it (given that Amazon calls it Barilla Ditalini Soup Cuts even though the term \"soup cuts\" does not appear on the package, or at least the package I got).\n",
            "\n",
            "\n",
            " user id : 9405 recommended item id : 4660 \n",
            " explanation :\n",
            " -  I'm glad the apple pieces are small, because they are REALLY sweet, and would overwhelm the mix if they were larger.Taken together, the ingredients in Sahale Classic Fruit + Nut Blend Trail Mix taste great to me.\n",
            " -  I would recommend NOT buying this in bulk (like I had the opportunity to do, more or less) unless you know you and/or your family REALLY enjoys/loves/favours this tasty treat.\n",
            " -  Like potato chips, these almonds can be addictive!Delicious but caloric snack -- if you're not counting calories, these are a great buy.\n",
            " -  This favor combination has quickly become a favorite.Both of these snack mixes are really good, with just the right balance of sweet and savory, crunchy and chewy, and nuts to fruit.\n",
            "\n",
            "\n",
            " user id : 9405 recommended item id : 6608 \n",
            " explanation :\n",
            " -  But these little pasta cylinders were actually very nice, and super easy to use.\n",
            " -  I was afraid they might dissolve completely, but they held up well and added a nice dimesion.Penne Plus (4 stars):  This is like the premium choice in Barilla, and so it is more expensive.\n",
            " -  None of the pieces stuck together, and had no problems twirling the pasta into the bowls I was serving dinner in.Dinner turned out well, and in a vote of confidence my other half commented on the linguine stating \"Well, it tastes like pasta\".\n",
            " -  But we tend to like this (angel hair is one of our top choices), so this was tasty enough.Oven Ready Lasagna (4 stars): I don't do lasagna very often and never from scratch!\n",
            "\n",
            "\n",
            " user id : 5259 recommended item id : 5319 \n",
            " explanation :\n",
            " -  Good Housekeeping said that one (Barilla Plus) tastes like \"white pasta,\" while the other (which like Barilla Whole Grain Thin Spaghetti is made with 51% whole wheat) \"earned points for its deliciously chewy texture and mildly nutty flavor.\n",
            " -  Barilla cooks much better and is ready to serve in minutes.Because this is a whole grain product, the goodness of the germ, endosperm, and fiber are all present.\n",
            " -  It offers a better alternative to traditional pastas which often take out some of the healthiest parts of the grain in order to make the taste more ordinary and acceptable.This spaghetti product cooks easily and the final product is stringy and ready for sauce or seasoning without clumping.\n",
            " -  Barilla Whole Grain Thin Spaghetti is a great tasting product that prepares fast and easily.\n",
            "\n",
            "\n",
            " user id : 5259 recommended item id : 6236 \n",
            " explanation :\n",
            " -  Thus, the great benefit of the HONEY MAIN FRESH STACKS product is not really \"freshness,\" but ease in packing an individual serving for school or trips.Now for the good part.\n",
            " -  Yet another reason for this new packaging is likely to prevent breakage, that might occur with the traditional rectangular crackers, during transportation.But a more likely reason is to allow people to take individual servings with them, perhaps on trips, to school, or to work, with the confidence that the crackers will be kept safe, secure, and intact.\n",
            " -  This will definitely allow those of us without lots of graham cracker eaters in the house to have fresh ones on hand.The perfect size for smores, these are packed as squares, or half the large rectangles we are used to.\n",
            " -  And Nabisco's Honey Maid is - after much testing of other manufacturers' competing product - easily the best graham cracker out there.\n",
            "\n",
            "\n",
            " user id : 5259 recommended item id : 2753 \n",
            " explanation :\n",
            " -  It probably doesn't matter; just a personal quirk, I guess.Anyway, this is good stuff: the taste is nice -- very good for sweetich things like carrots or plums, for example (I always have a bowl of very lightly steamed carrots around, and I snack on them, taking one and dipping it into CO, which is good for two reasons: first, it tastes great, and second, carotene is fat-soluble so you need to combine carrots with some sort of fat or it won't be used by the body well).All in all, there isn't much to say -- CO is CO is CO; this kind is no different from other types I've tried.\n",
            " -  ), even when close to 75 degrees - and for that reason, it is much better for use in baking, where a hard fat works much better than a soft one.But another characteristic of coconut oil that I love is its flavor and aroma - when you open the jar and stick your nose down in it, you are enveloped in the beauty of the coconut's best element, its aroma - its almost frightening how beautiful that smell is.\n",
            " -  Healthy fats, like this oil, will not affect insulin and give us much more stable energy that last longer in the body.5) Tastes great.\n",
            " -  This one is easily the best so far.The aroma is wonderful and the texture is much fuller than the other brands.\n",
            "\n",
            "\n",
            " user id : 5259 recommended item id : 593 \n",
            " explanation :\n",
            " -  Dark Magic DECAF is wonderfully strong and bold- quite similar to the regular, which happens to be my favorite kcup of all.\n",
            " -  A light blend should be FULL of a light flavor, and personally I didn't find this to be the case with GM's breakfast blend.Still, reading through the reviews it seems like many people enjoy the taste, and I won't fault them for it - coffee (like wine, cheese and most of gastronomy) is so subjective sometimes that there's no way I'm going to not recommend at least giving this a try to people who typically enjoy light blends.\n",
            " -  I received a couple of these Breakfast Blend K-Cups in a variety pack and decided to give them a shot - I've always been pretty pleased with Green Mountain coffee (several of their other blends are on my Wish List) and with them sitting there in the box  I figured \"why not?\"\n",
            " -  I was underwhelmed at most of them, but there were a few that were good enough to convince me that my Keurig COULD make an exceptional cup of coffee.\n",
            "\n",
            "\n",
            " user id : 5259 recommended item id : 3371 \n",
            " explanation :\n",
            " -  I would recommend this coconut oil to everyone because of it's many health benefits and versatility of use (You can spread it on your toast it tastes so great or cook with it as you would any cooking oil, as well as use it on your skin.\n",
            " -  I combine it with pure organic cold pressed olive oil- my hair loves it.The quality and texture are great.I like the containers- they're plastic jars which makes storing them a breeze.I also use this on my skin sometimes, and it works GREAT.\n",
            " -  I'm so glad I did, too, because this stuff is great and for a number of things, some of which caught me off guard.- Cooking -I enjoy cooking with it now and then, especially with my quick-fix quesadillas when I don't have time to cook anything else.\n",
            " -  The smell is strong, if you like coconut you'll love this.\n",
            "\n",
            "\n",
            " user id : 5259 recommended item id : 5324 \n",
            " explanation :\n",
            " -  Then when cool enough, I added the remaining ingredients.My nutritious lunch was discussed by a nutritionist, praised by the hikers, and enjoyed by all.\n",
            " -  I love this shape more than spaghetti or regular size penne for any dish that has a rich red sauce.\n",
            " -  I prepared some cooked to al dente perfection with a homemade sauce consisting of Parmesan cheese, milk, butter (unsalted), garlic, basil (dried from last year's garden) and fresh ground black pepper (I try to watch my sodium intake so I let everyone add salt at the table if they want), and it was a hit.Barilla is my go-to pasta brand when I shop for groceries.\n",
            " -  I chose to use the Mezze Penne n.369 to make a turkey pasta salad as part of a nutritious, energy boosting lunch for my charity hike team.Barilla, established in Parma Italy during 1877, is Italy's #1 brand of pasta.\n",
            "\n",
            "\n",
            " user id : 5259 recommended item id : 6863 \n",
            " explanation :\n",
            " -  I am VERY appreciative of the fact that Baby Gourmet makes a tasty product even adults can enjoy and further, that their label is ACCURATE by weight.As has been pointed out by fellow Vine Program member, Work of Life,  Happy Baby Organic Baby Food isn't quite so honest about their content.\n",
            " -  Intended for babies age 6 months and younger, this food offers infants the same natural food goodness that adults have been enjoying thanks to the organic/green movement.This baby food is loaded with vitamins for an infant's good health and well- being.\n",
            " -  Like  Vine Member, Work To Life, I highly rcommend the following book:Feeding Baby Green: The Earth Friendly Program for Healthy, Safe Nutrition During Pregnancy, Childhood, and Beyondand I also recommend the follow-up book by the same author,Raising Baby Green: The Earth-Friendly Guide to Pregnancy, Childbirth, and Baby Careto any of you who are striving to raise healthy children in a grocery store amnnd marketing world full of deceptive labels and advertising.\n",
            " -  In way way, that is good news, however, since that means the product gives your child 4% of the needed proten for the RDA (hopefully the rest is coming from breast milk or an approriate formula) 50% of the RDA for Vitamin A, 140% of the RDA for Vitamin C, no calicium to speak of even though spinach is supposed to be a good source (tells ya something) and 4 % of of the RDA for Iron.The biggest concern I have with this product is the packaging since that big plastic cap looks like a toy and if your child is clever enough to get it off the pouch once emptied, you know it's going stright into their mouth where it woull be chewed upon and possible choked upon.\n",
            "\n",
            "\n",
            " user id : 5259 recommended item id : 6256 \n",
            " explanation :\n",
            " -  This is truly a pasta that you can time to yield a perfect al dente firmness, which is important in soups because they tend to get reheated a number of times.In the customer-supplied images at the top of this page I've provided a photo of how my own recipe for Pasta e fagioli turns out.\n",
            " -  There are lots of great sounding recipes for ditalini to be found online that I'm eager to try (with names like Garlic and Leek Ditalini, Chicken Rollatini with Ditalini, and Lentils with Sopressata and Ditalini) and one can of course use their imagination.Barilla is my go-to pasta brand when I shop for groceries.\n",
            " -  There's a nice recipe on the box, Barilla Ditilini Soup with Barley and Potato that sounds scrumptious and has a prep time of only 15 minutes, 45 minutes to the table.This Barilla Ditalini will cook will cook up \"Al Dente\" in 10 - 11 minutes or if you want more tender pasta, cook an additional minute or two.\n",
            " -  Ditalini is a new pasta shape to me, and because I love to make big batches of homemade soup I was eager to try it (given that Amazon calls it Barilla Ditalini Soup Cuts even though the term \"soup cuts\" does not appear on the package, or at least the package I got).\n",
            "\n",
            "\n",
            " user id : 5259 recommended item id : 4660 \n",
            " explanation :\n",
            " -  I'm glad the apple pieces are small, because they are REALLY sweet, and would overwhelm the mix if they were larger.Taken together, the ingredients in Sahale Classic Fruit + Nut Blend Trail Mix taste great to me.\n",
            " -  I would recommend NOT buying this in bulk (like I had the opportunity to do, more or less) unless you know you and/or your family REALLY enjoys/loves/favours this tasty treat.\n",
            " -  Like potato chips, these almonds can be addictive!Delicious but caloric snack -- if you're not counting calories, these are a great buy.\n",
            " -  This favor combination has quickly become a favorite.Both of these snack mixes are really good, with just the right balance of sweet and savory, crunchy and chewy, and nuts to fruit.\n",
            "\n",
            "\n",
            " user id : 5259 recommended item id : 6608 \n",
            " explanation :\n",
            " -  But these little pasta cylinders were actually very nice, and super easy to use.\n",
            " -  I was afraid they might dissolve completely, but they held up well and added a nice dimesion.Penne Plus (4 stars):  This is like the premium choice in Barilla, and so it is more expensive.\n",
            " -  None of the pieces stuck together, and had no problems twirling the pasta into the bowls I was serving dinner in.Dinner turned out well, and in a vote of confidence my other half commented on the linguine stating \"Well, it tastes like pasta\".\n",
            " -  But we tend to like this (angel hair is one of our top choices), so this was tasty enough.Oven Ready Lasagna (4 stars): I don't do lasagna very often and never from scratch!\n",
            "\n",
            "\n",
            " user id : 4762 recommended item id : 5319 \n",
            " explanation :\n",
            " -  Good Housekeeping said that one (Barilla Plus) tastes like \"white pasta,\" while the other (which like Barilla Whole Grain Thin Spaghetti is made with 51% whole wheat) \"earned points for its deliciously chewy texture and mildly nutty flavor.\n",
            " -  Barilla cooks much better and is ready to serve in minutes.Because this is a whole grain product, the goodness of the germ, endosperm, and fiber are all present.\n",
            " -  It offers a better alternative to traditional pastas which often take out some of the healthiest parts of the grain in order to make the taste more ordinary and acceptable.This spaghetti product cooks easily and the final product is stringy and ready for sauce or seasoning without clumping.\n",
            " -  Barilla Whole Grain Thin Spaghetti is a great tasting product that prepares fast and easily.\n",
            "\n",
            "\n",
            " user id : 4762 recommended item id : 6236 \n",
            " explanation :\n",
            " -  Thus, the great benefit of the HONEY MAIN FRESH STACKS product is not really \"freshness,\" but ease in packing an individual serving for school or trips.Now for the good part.\n",
            " -  Yet another reason for this new packaging is likely to prevent breakage, that might occur with the traditional rectangular crackers, during transportation.But a more likely reason is to allow people to take individual servings with them, perhaps on trips, to school, or to work, with the confidence that the crackers will be kept safe, secure, and intact.\n",
            " -  This will definitely allow those of us without lots of graham cracker eaters in the house to have fresh ones on hand.The perfect size for smores, these are packed as squares, or half the large rectangles we are used to.\n",
            " -  And Nabisco's Honey Maid is - after much testing of other manufacturers' competing product - easily the best graham cracker out there.\n",
            "\n",
            "\n",
            " user id : 4762 recommended item id : 2753 \n",
            " explanation :\n",
            " -  It probably doesn't matter; just a personal quirk, I guess.Anyway, this is good stuff: the taste is nice -- very good for sweetich things like carrots or plums, for example (I always have a bowl of very lightly steamed carrots around, and I snack on them, taking one and dipping it into CO, which is good for two reasons: first, it tastes great, and second, carotene is fat-soluble so you need to combine carrots with some sort of fat or it won't be used by the body well).All in all, there isn't much to say -- CO is CO is CO; this kind is no different from other types I've tried.\n",
            " -  ), even when close to 75 degrees - and for that reason, it is much better for use in baking, where a hard fat works much better than a soft one.But another characteristic of coconut oil that I love is its flavor and aroma - when you open the jar and stick your nose down in it, you are enveloped in the beauty of the coconut's best element, its aroma - its almost frightening how beautiful that smell is.\n",
            " -  Healthy fats, like this oil, will not affect insulin and give us much more stable energy that last longer in the body.5) Tastes great.\n",
            " -  This one is easily the best so far.The aroma is wonderful and the texture is much fuller than the other brands.\n",
            "\n",
            "\n",
            " user id : 4762 recommended item id : 593 \n",
            " explanation :\n",
            " -  Dark Magic DECAF is wonderfully strong and bold- quite similar to the regular, which happens to be my favorite kcup of all.\n",
            " -  A light blend should be FULL of a light flavor, and personally I didn't find this to be the case with GM's breakfast blend.Still, reading through the reviews it seems like many people enjoy the taste, and I won't fault them for it - coffee (like wine, cheese and most of gastronomy) is so subjective sometimes that there's no way I'm going to not recommend at least giving this a try to people who typically enjoy light blends.\n",
            " -  I received a couple of these Breakfast Blend K-Cups in a variety pack and decided to give them a shot - I've always been pretty pleased with Green Mountain coffee (several of their other blends are on my Wish List) and with them sitting there in the box  I figured \"why not?\"\n",
            " -  I was underwhelmed at most of them, but there were a few that were good enough to convince me that my Keurig COULD make an exceptional cup of coffee.\n",
            "\n",
            "\n",
            " user id : 4762 recommended item id : 3371 \n",
            " explanation :\n",
            " -  I would recommend this coconut oil to everyone because of it's many health benefits and versatility of use (You can spread it on your toast it tastes so great or cook with it as you would any cooking oil, as well as use it on your skin.\n",
            " -  I combine it with pure organic cold pressed olive oil- my hair loves it.The quality and texture are great.I like the containers- they're plastic jars which makes storing them a breeze.I also use this on my skin sometimes, and it works GREAT.\n",
            " -  I'm so glad I did, too, because this stuff is great and for a number of things, some of which caught me off guard.- Cooking -I enjoy cooking with it now and then, especially with my quick-fix quesadillas when I don't have time to cook anything else.\n",
            " -  The smell is strong, if you like coconut you'll love this.\n",
            "\n",
            "\n",
            " user id : 4762 recommended item id : 6863 \n",
            " explanation :\n",
            " -  I am VERY appreciative of the fact that Baby Gourmet makes a tasty product even adults can enjoy and further, that their label is ACCURATE by weight.As has been pointed out by fellow Vine Program member, Work of Life,  Happy Baby Organic Baby Food isn't quite so honest about their content.\n",
            " -  Intended for babies age 6 months and younger, this food offers infants the same natural food goodness that adults have been enjoying thanks to the organic/green movement.This baby food is loaded with vitamins for an infant's good health and well- being.\n",
            " -  Like  Vine Member, Work To Life, I highly rcommend the following book:Feeding Baby Green: The Earth Friendly Program for Healthy, Safe Nutrition During Pregnancy, Childhood, and Beyondand I also recommend the follow-up book by the same author,Raising Baby Green: The Earth-Friendly Guide to Pregnancy, Childbirth, and Baby Careto any of you who are striving to raise healthy children in a grocery store amnnd marketing world full of deceptive labels and advertising.\n",
            " -  In way way, that is good news, however, since that means the product gives your child 4% of the needed proten for the RDA (hopefully the rest is coming from breast milk or an approriate formula) 50% of the RDA for Vitamin A, 140% of the RDA for Vitamin C, no calicium to speak of even though spinach is supposed to be a good source (tells ya something) and 4 % of of the RDA for Iron.The biggest concern I have with this product is the packaging since that big plastic cap looks like a toy and if your child is clever enough to get it off the pouch once emptied, you know it's going stright into their mouth where it woull be chewed upon and possible choked upon.\n",
            "\n",
            "\n",
            " user id : 4762 recommended item id : 5324 \n",
            " explanation :\n",
            " -  Then when cool enough, I added the remaining ingredients.My nutritious lunch was discussed by a nutritionist, praised by the hikers, and enjoyed by all.\n",
            " -  I love this shape more than spaghetti or regular size penne for any dish that has a rich red sauce.\n",
            " -  I prepared some cooked to al dente perfection with a homemade sauce consisting of Parmesan cheese, milk, butter (unsalted), garlic, basil (dried from last year's garden) and fresh ground black pepper (I try to watch my sodium intake so I let everyone add salt at the table if they want), and it was a hit.Barilla is my go-to pasta brand when I shop for groceries.\n",
            " -  I chose to use the Mezze Penne n.369 to make a turkey pasta salad as part of a nutritious, energy boosting lunch for my charity hike team.Barilla, established in Parma Italy during 1877, is Italy's #1 brand of pasta.\n",
            "\n",
            "\n",
            " user id : 4762 recommended item id : 6256 \n",
            " explanation :\n",
            " -  This is truly a pasta that you can time to yield a perfect al dente firmness, which is important in soups because they tend to get reheated a number of times.In the customer-supplied images at the top of this page I've provided a photo of how my own recipe for Pasta e fagioli turns out.\n",
            " -  There are lots of great sounding recipes for ditalini to be found online that I'm eager to try (with names like Garlic and Leek Ditalini, Chicken Rollatini with Ditalini, and Lentils with Sopressata and Ditalini) and one can of course use their imagination.Barilla is my go-to pasta brand when I shop for groceries.\n",
            " -  There's a nice recipe on the box, Barilla Ditilini Soup with Barley and Potato that sounds scrumptious and has a prep time of only 15 minutes, 45 minutes to the table.This Barilla Ditalini will cook will cook up \"Al Dente\" in 10 - 11 minutes or if you want more tender pasta, cook an additional minute or two.\n",
            " -  Ditalini is a new pasta shape to me, and because I love to make big batches of homemade soup I was eager to try it (given that Amazon calls it Barilla Ditalini Soup Cuts even though the term \"soup cuts\" does not appear on the package, or at least the package I got).\n",
            "\n",
            "\n",
            " user id : 4762 recommended item id : 4660 \n",
            " explanation :\n",
            " -  I'm glad the apple pieces are small, because they are REALLY sweet, and would overwhelm the mix if they were larger.Taken together, the ingredients in Sahale Classic Fruit + Nut Blend Trail Mix taste great to me.\n",
            " -  I would recommend NOT buying this in bulk (like I had the opportunity to do, more or less) unless you know you and/or your family REALLY enjoys/loves/favours this tasty treat.\n",
            " -  Like potato chips, these almonds can be addictive!Delicious but caloric snack -- if you're not counting calories, these are a great buy.\n",
            " -  This favor combination has quickly become a favorite.Both of these snack mixes are really good, with just the right balance of sweet and savory, crunchy and chewy, and nuts to fruit.\n",
            "\n",
            "\n",
            " user id : 4762 recommended item id : 6608 \n",
            " explanation :\n",
            " -  But these little pasta cylinders were actually very nice, and super easy to use.\n",
            " -  I was afraid they might dissolve completely, but they held up well and added a nice dimesion.Penne Plus (4 stars):  This is like the premium choice in Barilla, and so it is more expensive.\n",
            " -  None of the pieces stuck together, and had no problems twirling the pasta into the bowls I was serving dinner in.Dinner turned out well, and in a vote of confidence my other half commented on the linguine stating \"Well, it tastes like pasta\".\n",
            " -  But we tend to like this (angel hair is one of our top choices), so this was tasty enough.Oven Ready Lasagna (4 stars): I don't do lasagna very often and never from scratch!\n",
            "\n",
            "\n",
            " user id : 190 recommended item id : 5319 \n",
            " explanation :\n",
            " -  Good Housekeeping said that one (Barilla Plus) tastes like \"white pasta,\" while the other (which like Barilla Whole Grain Thin Spaghetti is made with 51% whole wheat) \"earned points for its deliciously chewy texture and mildly nutty flavor.\n",
            " -  Barilla cooks much better and is ready to serve in minutes.Because this is a whole grain product, the goodness of the germ, endosperm, and fiber are all present.\n",
            " -  It offers a better alternative to traditional pastas which often take out some of the healthiest parts of the grain in order to make the taste more ordinary and acceptable.This spaghetti product cooks easily and the final product is stringy and ready for sauce or seasoning without clumping.\n",
            " -  Barilla Whole Grain Thin Spaghetti is a great tasting product that prepares fast and easily.\n",
            "\n",
            "\n",
            " user id : 190 recommended item id : 6236 \n",
            " explanation :\n",
            " -  Thus, the great benefit of the HONEY MAIN FRESH STACKS product is not really \"freshness,\" but ease in packing an individual serving for school or trips.Now for the good part.\n",
            " -  Yet another reason for this new packaging is likely to prevent breakage, that might occur with the traditional rectangular crackers, during transportation.But a more likely reason is to allow people to take individual servings with them, perhaps on trips, to school, or to work, with the confidence that the crackers will be kept safe, secure, and intact.\n",
            " -  This will definitely allow those of us without lots of graham cracker eaters in the house to have fresh ones on hand.The perfect size for smores, these are packed as squares, or half the large rectangles we are used to.\n",
            " -  And Nabisco's Honey Maid is - after much testing of other manufacturers' competing product - easily the best graham cracker out there.\n",
            "\n",
            "\n",
            " user id : 190 recommended item id : 2753 \n",
            " explanation :\n",
            " -  It probably doesn't matter; just a personal quirk, I guess.Anyway, this is good stuff: the taste is nice -- very good for sweetich things like carrots or plums, for example (I always have a bowl of very lightly steamed carrots around, and I snack on them, taking one and dipping it into CO, which is good for two reasons: first, it tastes great, and second, carotene is fat-soluble so you need to combine carrots with some sort of fat or it won't be used by the body well).All in all, there isn't much to say -- CO is CO is CO; this kind is no different from other types I've tried.\n",
            " -  ), even when close to 75 degrees - and for that reason, it is much better for use in baking, where a hard fat works much better than a soft one.But another characteristic of coconut oil that I love is its flavor and aroma - when you open the jar and stick your nose down in it, you are enveloped in the beauty of the coconut's best element, its aroma - its almost frightening how beautiful that smell is.\n",
            " -  Healthy fats, like this oil, will not affect insulin and give us much more stable energy that last longer in the body.5) Tastes great.\n",
            " -  This one is easily the best so far.The aroma is wonderful and the texture is much fuller than the other brands.\n",
            "\n",
            "\n",
            " user id : 190 recommended item id : 593 \n",
            " explanation :\n",
            " -  Dark Magic DECAF is wonderfully strong and bold- quite similar to the regular, which happens to be my favorite kcup of all.\n",
            " -  A light blend should be FULL of a light flavor, and personally I didn't find this to be the case with GM's breakfast blend.Still, reading through the reviews it seems like many people enjoy the taste, and I won't fault them for it - coffee (like wine, cheese and most of gastronomy) is so subjective sometimes that there's no way I'm going to not recommend at least giving this a try to people who typically enjoy light blends.\n",
            " -  I received a couple of these Breakfast Blend K-Cups in a variety pack and decided to give them a shot - I've always been pretty pleased with Green Mountain coffee (several of their other blends are on my Wish List) and with them sitting there in the box  I figured \"why not?\"\n",
            " -  I was underwhelmed at most of them, but there were a few that were good enough to convince me that my Keurig COULD make an exceptional cup of coffee.\n",
            "\n",
            "\n",
            " user id : 190 recommended item id : 3371 \n",
            " explanation :\n",
            " -  I would recommend this coconut oil to everyone because of it's many health benefits and versatility of use (You can spread it on your toast it tastes so great or cook with it as you would any cooking oil, as well as use it on your skin.\n",
            " -  I combine it with pure organic cold pressed olive oil- my hair loves it.The quality and texture are great.I like the containers- they're plastic jars which makes storing them a breeze.I also use this on my skin sometimes, and it works GREAT.\n",
            " -  I'm so glad I did, too, because this stuff is great and for a number of things, some of which caught me off guard.- Cooking -I enjoy cooking with it now and then, especially with my quick-fix quesadillas when I don't have time to cook anything else.\n",
            " -  The smell is strong, if you like coconut you'll love this.\n",
            "\n",
            "\n",
            " user id : 190 recommended item id : 5324 \n",
            " explanation :\n",
            " -  Then when cool enough, I added the remaining ingredients.My nutritious lunch was discussed by a nutritionist, praised by the hikers, and enjoyed by all.\n",
            " -  I love this shape more than spaghetti or regular size penne for any dish that has a rich red sauce.\n",
            " -  I prepared some cooked to al dente perfection with a homemade sauce consisting of Parmesan cheese, milk, butter (unsalted), garlic, basil (dried from last year's garden) and fresh ground black pepper (I try to watch my sodium intake so I let everyone add salt at the table if they want), and it was a hit.Barilla is my go-to pasta brand when I shop for groceries.\n",
            " -  I chose to use the Mezze Penne n.369 to make a turkey pasta salad as part of a nutritious, energy boosting lunch for my charity hike team.Barilla, established in Parma Italy during 1877, is Italy's #1 brand of pasta.\n",
            "\n",
            "\n",
            " user id : 190 recommended item id : 6863 \n",
            " explanation :\n",
            " -  I am VERY appreciative of the fact that Baby Gourmet makes a tasty product even adults can enjoy and further, that their label is ACCURATE by weight.As has been pointed out by fellow Vine Program member, Work of Life,  Happy Baby Organic Baby Food isn't quite so honest about their content.\n",
            " -  Intended for babies age 6 months and younger, this food offers infants the same natural food goodness that adults have been enjoying thanks to the organic/green movement.This baby food is loaded with vitamins for an infant's good health and well- being.\n",
            " -  Like  Vine Member, Work To Life, I highly rcommend the following book:Feeding Baby Green: The Earth Friendly Program for Healthy, Safe Nutrition During Pregnancy, Childhood, and Beyondand I also recommend the follow-up book by the same author,Raising Baby Green: The Earth-Friendly Guide to Pregnancy, Childbirth, and Baby Careto any of you who are striving to raise healthy children in a grocery store amnnd marketing world full of deceptive labels and advertising.\n",
            " -  In way way, that is good news, however, since that means the product gives your child 4% of the needed proten for the RDA (hopefully the rest is coming from breast milk or an approriate formula) 50% of the RDA for Vitamin A, 140% of the RDA for Vitamin C, no calicium to speak of even though spinach is supposed to be a good source (tells ya something) and 4 % of of the RDA for Iron.The biggest concern I have with this product is the packaging since that big plastic cap looks like a toy and if your child is clever enough to get it off the pouch once emptied, you know it's going stright into their mouth where it woull be chewed upon and possible choked upon.\n",
            "\n",
            "\n",
            " user id : 190 recommended item id : 6256 \n",
            " explanation :\n",
            " -  This is truly a pasta that you can time to yield a perfect al dente firmness, which is important in soups because they tend to get reheated a number of times.In the customer-supplied images at the top of this page I've provided a photo of how my own recipe for Pasta e fagioli turns out.\n",
            " -  There are lots of great sounding recipes for ditalini to be found online that I'm eager to try (with names like Garlic and Leek Ditalini, Chicken Rollatini with Ditalini, and Lentils with Sopressata and Ditalini) and one can of course use their imagination.Barilla is my go-to pasta brand when I shop for groceries.\n",
            " -  There's a nice recipe on the box, Barilla Ditilini Soup with Barley and Potato that sounds scrumptious and has a prep time of only 15 minutes, 45 minutes to the table.This Barilla Ditalini will cook will cook up \"Al Dente\" in 10 - 11 minutes or if you want more tender pasta, cook an additional minute or two.\n",
            " -  Ditalini is a new pasta shape to me, and because I love to make big batches of homemade soup I was eager to try it (given that Amazon calls it Barilla Ditalini Soup Cuts even though the term \"soup cuts\" does not appear on the package, or at least the package I got).\n",
            "\n",
            "\n",
            " user id : 190 recommended item id : 4660 \n",
            " explanation :\n",
            " -  I'm glad the apple pieces are small, because they are REALLY sweet, and would overwhelm the mix if they were larger.Taken together, the ingredients in Sahale Classic Fruit + Nut Blend Trail Mix taste great to me.\n",
            " -  I would recommend NOT buying this in bulk (like I had the opportunity to do, more or less) unless you know you and/or your family REALLY enjoys/loves/favours this tasty treat.\n",
            " -  Like potato chips, these almonds can be addictive!Delicious but caloric snack -- if you're not counting calories, these are a great buy.\n",
            " -  This favor combination has quickly become a favorite.Both of these snack mixes are really good, with just the right balance of sweet and savory, crunchy and chewy, and nuts to fruit.\n",
            "\n",
            "\n",
            " user id : 190 recommended item id : 6608 \n",
            " explanation :\n",
            " -  But these little pasta cylinders were actually very nice, and super easy to use.\n",
            " -  I was afraid they might dissolve completely, but they held up well and added a nice dimesion.Penne Plus (4 stars):  This is like the premium choice in Barilla, and so it is more expensive.\n",
            " -  None of the pieces stuck together, and had no problems twirling the pasta into the bowls I was serving dinner in.Dinner turned out well, and in a vote of confidence my other half commented on the linguine stating \"Well, it tastes like pasta\".\n",
            " -  But we tend to like this (angel hair is one of our top choices), so this was tasty enough.Oven Ready Lasagna (4 stars): I don't do lasagna very often and never from scratch!\n",
            "\n",
            "\n",
            " user id : 2021 recommended item id : 5319 \n",
            " explanation :\n",
            " -  Good Housekeeping said that one (Barilla Plus) tastes like \"white pasta,\" while the other (which like Barilla Whole Grain Thin Spaghetti is made with 51% whole wheat) \"earned points for its deliciously chewy texture and mildly nutty flavor.\n",
            " -  Barilla cooks much better and is ready to serve in minutes.Because this is a whole grain product, the goodness of the germ, endosperm, and fiber are all present.\n",
            " -  It offers a better alternative to traditional pastas which often take out some of the healthiest parts of the grain in order to make the taste more ordinary and acceptable.This spaghetti product cooks easily and the final product is stringy and ready for sauce or seasoning without clumping.\n",
            " -  Barilla Whole Grain Thin Spaghetti is a great tasting product that prepares fast and easily.\n",
            "\n",
            "\n",
            " user id : 2021 recommended item id : 6236 \n",
            " explanation :\n",
            " -  Thus, the great benefit of the HONEY MAIN FRESH STACKS product is not really \"freshness,\" but ease in packing an individual serving for school or trips.Now for the good part.\n",
            " -  Yet another reason for this new packaging is likely to prevent breakage, that might occur with the traditional rectangular crackers, during transportation.But a more likely reason is to allow people to take individual servings with them, perhaps on trips, to school, or to work, with the confidence that the crackers will be kept safe, secure, and intact.\n",
            " -  This will definitely allow those of us without lots of graham cracker eaters in the house to have fresh ones on hand.The perfect size for smores, these are packed as squares, or half the large rectangles we are used to.\n",
            " -  And Nabisco's Honey Maid is - after much testing of other manufacturers' competing product - easily the best graham cracker out there.\n",
            "\n",
            "\n",
            " user id : 2021 recommended item id : 2753 \n",
            " explanation :\n",
            " -  It probably doesn't matter; just a personal quirk, I guess.Anyway, this is good stuff: the taste is nice -- very good for sweetich things like carrots or plums, for example (I always have a bowl of very lightly steamed carrots around, and I snack on them, taking one and dipping it into CO, which is good for two reasons: first, it tastes great, and second, carotene is fat-soluble so you need to combine carrots with some sort of fat or it won't be used by the body well).All in all, there isn't much to say -- CO is CO is CO; this kind is no different from other types I've tried.\n",
            " -  ), even when close to 75 degrees - and for that reason, it is much better for use in baking, where a hard fat works much better than a soft one.But another characteristic of coconut oil that I love is its flavor and aroma - when you open the jar and stick your nose down in it, you are enveloped in the beauty of the coconut's best element, its aroma - its almost frightening how beautiful that smell is.\n",
            " -  Healthy fats, like this oil, will not affect insulin and give us much more stable energy that last longer in the body.5) Tastes great.\n",
            " -  This one is easily the best so far.The aroma is wonderful and the texture is much fuller than the other brands.\n",
            "\n",
            "\n",
            " user id : 2021 recommended item id : 593 \n",
            " explanation :\n",
            " -  Dark Magic DECAF is wonderfully strong and bold- quite similar to the regular, which happens to be my favorite kcup of all.\n",
            " -  A light blend should be FULL of a light flavor, and personally I didn't find this to be the case with GM's breakfast blend.Still, reading through the reviews it seems like many people enjoy the taste, and I won't fault them for it - coffee (like wine, cheese and most of gastronomy) is so subjective sometimes that there's no way I'm going to not recommend at least giving this a try to people who typically enjoy light blends.\n",
            " -  I received a couple of these Breakfast Blend K-Cups in a variety pack and decided to give them a shot - I've always been pretty pleased with Green Mountain coffee (several of their other blends are on my Wish List) and with them sitting there in the box  I figured \"why not?\"\n",
            " -  I was underwhelmed at most of them, but there were a few that were good enough to convince me that my Keurig COULD make an exceptional cup of coffee.\n",
            "\n",
            "\n",
            " user id : 2021 recommended item id : 3371 \n",
            " explanation :\n",
            " -  I would recommend this coconut oil to everyone because of it's many health benefits and versatility of use (You can spread it on your toast it tastes so great or cook with it as you would any cooking oil, as well as use it on your skin.\n",
            " -  I combine it with pure organic cold pressed olive oil- my hair loves it.The quality and texture are great.I like the containers- they're plastic jars which makes storing them a breeze.I also use this on my skin sometimes, and it works GREAT.\n",
            " -  I'm so glad I did, too, because this stuff is great and for a number of things, some of which caught me off guard.- Cooking -I enjoy cooking with it now and then, especially with my quick-fix quesadillas when I don't have time to cook anything else.\n",
            " -  The smell is strong, if you like coconut you'll love this.\n",
            "\n",
            "\n",
            " user id : 2021 recommended item id : 5324 \n",
            " explanation :\n",
            " -  Then when cool enough, I added the remaining ingredients.My nutritious lunch was discussed by a nutritionist, praised by the hikers, and enjoyed by all.\n",
            " -  I love this shape more than spaghetti or regular size penne for any dish that has a rich red sauce.\n",
            " -  I prepared some cooked to al dente perfection with a homemade sauce consisting of Parmesan cheese, milk, butter (unsalted), garlic, basil (dried from last year's garden) and fresh ground black pepper (I try to watch my sodium intake so I let everyone add salt at the table if they want), and it was a hit.Barilla is my go-to pasta brand when I shop for groceries.\n",
            " -  I chose to use the Mezze Penne n.369 to make a turkey pasta salad as part of a nutritious, energy boosting lunch for my charity hike team.Barilla, established in Parma Italy during 1877, is Italy's #1 brand of pasta.\n",
            "\n",
            "\n",
            " user id : 2021 recommended item id : 6863 \n",
            " explanation :\n",
            " -  I am VERY appreciative of the fact that Baby Gourmet makes a tasty product even adults can enjoy and further, that their label is ACCURATE by weight.As has been pointed out by fellow Vine Program member, Work of Life,  Happy Baby Organic Baby Food isn't quite so honest about their content.\n",
            " -  Intended for babies age 6 months and younger, this food offers infants the same natural food goodness that adults have been enjoying thanks to the organic/green movement.This baby food is loaded with vitamins for an infant's good health and well- being.\n",
            " -  Like  Vine Member, Work To Life, I highly rcommend the following book:Feeding Baby Green: The Earth Friendly Program for Healthy, Safe Nutrition During Pregnancy, Childhood, and Beyondand I also recommend the follow-up book by the same author,Raising Baby Green: The Earth-Friendly Guide to Pregnancy, Childbirth, and Baby Careto any of you who are striving to raise healthy children in a grocery store amnnd marketing world full of deceptive labels and advertising.\n",
            " -  In way way, that is good news, however, since that means the product gives your child 4% of the needed proten for the RDA (hopefully the rest is coming from breast milk or an approriate formula) 50% of the RDA for Vitamin A, 140% of the RDA for Vitamin C, no calicium to speak of even though spinach is supposed to be a good source (tells ya something) and 4 % of of the RDA for Iron.The biggest concern I have with this product is the packaging since that big plastic cap looks like a toy and if your child is clever enough to get it off the pouch once emptied, you know it's going stright into their mouth where it woull be chewed upon and possible choked upon.\n",
            "\n",
            "\n",
            " user id : 2021 recommended item id : 6256 \n",
            " explanation :\n",
            " -  This is truly a pasta that you can time to yield a perfect al dente firmness, which is important in soups because they tend to get reheated a number of times.In the customer-supplied images at the top of this page I've provided a photo of how my own recipe for Pasta e fagioli turns out.\n",
            " -  There are lots of great sounding recipes for ditalini to be found online that I'm eager to try (with names like Garlic and Leek Ditalini, Chicken Rollatini with Ditalini, and Lentils with Sopressata and Ditalini) and one can of course use their imagination.Barilla is my go-to pasta brand when I shop for groceries.\n",
            " -  There's a nice recipe on the box, Barilla Ditilini Soup with Barley and Potato that sounds scrumptious and has a prep time of only 15 minutes, 45 minutes to the table.This Barilla Ditalini will cook will cook up \"Al Dente\" in 10 - 11 minutes or if you want more tender pasta, cook an additional minute or two.\n",
            " -  Ditalini is a new pasta shape to me, and because I love to make big batches of homemade soup I was eager to try it (given that Amazon calls it Barilla Ditalini Soup Cuts even though the term \"soup cuts\" does not appear on the package, or at least the package I got).\n",
            "\n",
            "\n",
            " user id : 2021 recommended item id : 4660 \n",
            " explanation :\n",
            " -  I'm glad the apple pieces are small, because they are REALLY sweet, and would overwhelm the mix if they were larger.Taken together, the ingredients in Sahale Classic Fruit + Nut Blend Trail Mix taste great to me.\n",
            " -  I would recommend NOT buying this in bulk (like I had the opportunity to do, more or less) unless you know you and/or your family REALLY enjoys/loves/favours this tasty treat.\n",
            " -  Like potato chips, these almonds can be addictive!Delicious but caloric snack -- if you're not counting calories, these are a great buy.\n",
            " -  This favor combination has quickly become a favorite.Both of these snack mixes are really good, with just the right balance of sweet and savory, crunchy and chewy, and nuts to fruit.\n",
            "\n",
            "\n",
            " user id : 2021 recommended item id : 6608 \n",
            " explanation :\n",
            " -  But these little pasta cylinders were actually very nice, and super easy to use.\n",
            " -  I was afraid they might dissolve completely, but they held up well and added a nice dimesion.Penne Plus (4 stars):  This is like the premium choice in Barilla, and so it is more expensive.\n",
            " -  None of the pieces stuck together, and had no problems twirling the pasta into the bowls I was serving dinner in.Dinner turned out well, and in a vote of confidence my other half commented on the linguine stating \"Well, it tastes like pasta\".\n",
            " -  But we tend to like this (angel hair is one of our top choices), so this was tasty enough.Oven Ready Lasagna (4 stars): I don't do lasagna very often and never from scratch!\n"
          ]
        }
      ],
      "source": [
        "mt_model.predict(5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Explainable Recommender System.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('colabenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "5859fc1fd51a29bc96a6c335b5cef2533de774a99a73e1484108bae0d11f06ff"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
