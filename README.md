# A Framework for Generating Explainable Recommendations via Multi-Task Learning

## üìñ Abstract
Recommendation systems predict items or services that users might find desirable based on their past interactions (e.g., ratings, likes, shopping history). However, these systems face several challenges:  

1. **Data insufficiency** ‚Äì limited information about user preferences.  
2. **Lack of transparency** ‚Äì users cannot understand why items are recommended.  

Leveraging **user reviews** can help address these challenges:  
- Reviews convey user preferences, providing **additional data** for better recommendations.  
- Reviews can generate **textual explanations**, improving transparency.

With the growing attention to **Responsible AI (RAI)**, it is increasingly important for recommender systems to provide **explainable recommendations**. Transparency, a key principle of RAI, allows users to understand the reasoning behind AI predictions. Therefore, e-commerce platforms and other systems using recommender models should provide explanations to act responsibly.

While text-based explanations are common in many explainable recommendation systems, prior works often neglect the **writing style of users**, which can impact the effectiveness of explanations.  

The main goal of this work is to develop a **novel framework** that generates explainable recommendations by incorporating both **user preferences** and **user writing styles** into the explanation generation process.

---

## üñºÔ∏è Framework Diagram
<img width="653" alt="Framework Diagram" src="https://user-images.githubusercontent.com/103757072/233791305-44be5fa7-e794-411e-8863-c7709ec389ef.png">
<img width="653" alt="Framework Diagram" src="exp_main_diagram.png">
---

## üîë Keywords
- Recommender System  
- Responsible AI  
- Multi-Task Learning  
- Explanation Generation  
- Explainable Recommendation  
- Text Reconstruction

---

## ‚öôÔ∏è Highlights
- Incorporates user **writing style** into explanation generation.  
- Uses **multi-task learning** to predict recommendations and generate explanations simultaneously.  
- Promotes **transparency and ethical AI practices** in recommendation systems.  
